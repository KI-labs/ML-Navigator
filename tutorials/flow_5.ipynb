{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"flow_5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35mWelcome to the Data Science Package. First create an object as follows:\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example, use the code below to import the flow 0:\u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mflow = Flows(0)\u001b[m\n",
      "\u001b[1m\u001b[35mYou can define the `categorical_threshold` which is the maximum number of categories that a categorical feature should have before considering it as continuous numeric feature. The default value is 50\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example, use the code below to import the flow 0 with defining the categorical_threshold as 50\u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mflow = Flows(flow_id=0, categorical_threshold=50)\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from flows.flows import Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35mPlease use the following function to read the data\u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.load_data(path : str, files_list : list)\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mpath = ./data\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mIf your data is in a nested directory, it is better to os.path.join. For example:\n",
      "\u001b[m\u001b[32m\u001b[40mpath = os.path.join('data', 'flow_0')\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mfiles_list = ['train.csv','test.csv']\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mThe output is a dictionary that contains dataframes e.g.\n",
      "\u001b[m\u001b[m\n",
      "\u001b[34mdataframe_dict = {'train': train_dataframe,'test': test_dataframe}\u001b[m\n",
      "\u001b[1m\u001b[35mIf you want to explore the data you can run one of the following functions: \u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35m1 . \u001b[m\u001b[32m\u001b[40mflow.exploring_data(dataframe_dict: dict, key_i: str)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mflow.exploring_data(dataframe_dict, 'train')\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35m2 . \u001b[m\u001b[32m\u001b[40mflow.comparing_statistics(dataframe_dict: dict)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mflow.comparing_statistics(dataframe_dict)\u001b[m\u001b[m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flow = Flows(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/flow_3\" # the flow applied to the same data in flow_3\n",
    "files_list = ['train_transaction.csv','test_transaction.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_transaction</th>\n",
       "      <th>test_transaction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>326</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>394</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_transaction  test_transaction\n",
       "column type                                             \n",
       "categorical_integer                326               325\n",
       "categorical_string                  14                14\n",
       "continuous                          54                54\n",
       "date                                 0                 0\n",
       "json                                 0                 0\n",
       "other                                0                 0\n",
       "total amount                       394               393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "The possible ids are:\n",
      " {'TransactionID'}\n",
      "The possible possible_target are:\n",
      " ['isFraud']\n",
      "The type of the problem that should be solved:\n",
      " {'isFraud': 'classification'}\n",
      "\n",
      "The Kullback-Leibler Divergence between probability mass function (pmf) derived from `isFraud` and and an uniformly distributed pmf \t = 1.257 \n",
      "It is above the threshold \t 0.050. \n",
      "Imballanced target variable!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total count</th>\n",
       "      <th>frequency (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isFraud values</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1469</td>\n",
       "      <td>97.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>2.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                total count  frequency (%)\n",
       "isFraud values                            \n",
       "0                      1469          97.93\n",
       "1                        31           2.07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35mIf you have categorical features with string labels, Encode the categorical features by applying the following function:\n",
      "\u001b[m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.encode_categorical_feature(dataframe_dict: dict)\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.load_data(path, files_list, rows_amount=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>V330</th>\n",
       "      <th>V331</th>\n",
       "      <th>V332</th>\n",
       "      <th>V333</th>\n",
       "      <th>V334</th>\n",
       "      <th>V335</th>\n",
       "      <th>V336</th>\n",
       "      <th>V337</th>\n",
       "      <th>V338</th>\n",
       "      <th>V339</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2987000</td>\n",
       "      <td>0</td>\n",
       "      <td>86400</td>\n",
       "      <td>68.5</td>\n",
       "      <td>W</td>\n",
       "      <td>13926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>discover</td>\n",
       "      <td>142.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2987001</td>\n",
       "      <td>0</td>\n",
       "      <td>86401</td>\n",
       "      <td>29.0</td>\n",
       "      <td>W</td>\n",
       "      <td>2755</td>\n",
       "      <td>404.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2987002</td>\n",
       "      <td>0</td>\n",
       "      <td>86469</td>\n",
       "      <td>59.0</td>\n",
       "      <td>W</td>\n",
       "      <td>4663</td>\n",
       "      <td>490.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2987003</td>\n",
       "      <td>0</td>\n",
       "      <td>86499</td>\n",
       "      <td>50.0</td>\n",
       "      <td>W</td>\n",
       "      <td>18132</td>\n",
       "      <td>567.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2987004</td>\n",
       "      <td>0</td>\n",
       "      <td>86506</td>\n",
       "      <td>50.0</td>\n",
       "      <td>H</td>\n",
       "      <td>4497</td>\n",
       "      <td>514.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2987000        0          86400            68.5         W  13926   \n",
       "1        2987001        0          86401            29.0         W   2755   \n",
       "2        2987002        0          86469            59.0         W   4663   \n",
       "3        2987003        0          86499            50.0         W  18132   \n",
       "4        2987004        0          86506            50.0         H   4497   \n",
       "\n",
       "   card2  card3       card4  card5  ... V330  V331  V332  V333  V334 V335  \\\n",
       "0    NaN  150.0    discover  142.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "1  404.0  150.0  mastercard  102.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "2  490.0  150.0        visa  166.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "3  567.0  150.0  mastercard  117.0  ...  NaN   NaN   NaN   NaN   NaN  NaN   \n",
       "4  514.0  150.0  mastercard  102.0  ...  0.0   0.0   0.0   0.0   0.0  0.0   \n",
       "\n",
       "  V336  V337  V338  V339  \n",
       "0  NaN   NaN   NaN   NaN  \n",
       "1  NaN   NaN   NaN   NaN  \n",
       "2  NaN   NaN   NaN   NaN  \n",
       "3  NaN   NaN   NaN   NaN  \n",
       "4  0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_dict[\"train_transaction\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['categorical_string', 'categorical_integer', 'continuous', 'date', 'json', 'other'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " columns_set[\"train_transaction\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the second dataset similar to the first dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_identity</th>\n",
       "      <th>test_identity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train_identity  test_identity\n",
       "column type                                       \n",
       "categorical_integer              18             20\n",
       "categorical_string               17             17\n",
       "continuous                        6              4\n",
       "date                              0              0\n",
       "json                              0              0\n",
       "other                             0              0\n",
       "total amount                     41             41"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "The possible ids are:\n",
      " {'TransactionID'}\n",
      "The possible possible_target are:\n",
      " Too many options for target. Not possible to detect target\n",
      "The type of the problem that should be solved:\n",
      " No problem type to detect\n",
      "Not possible to check if the target is imbalanced\n",
      "Error is:\n",
      " 'str' object has no attribute 'items'\n",
      "\u001b[1m\u001b[35mIf you have categorical features with string labels, Encode the categorical features by applying the following function:\n",
      "\u001b[m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.encode_categorical_feature(dataframe_dict: dict)\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "files_list_2 = ['train_identity.csv','test_identity.csv']\n",
    "dataframe_dict_identity, columns_set_identity = flow.load_data(path, files_list_2, rows_amount=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will merge both datasets. This causes that we diverge from the flow that we load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe_train =  pd.merge(dataframe_dict[\"train_transaction\"],\n",
    "                            dataframe_dict_identity[\"train_identity\"],\n",
    "                            on='TransactionID') \n",
    "dataframe_test = pd.merge(dataframe_dict[\"test_transaction\"],\n",
    "                            dataframe_dict_identity[\"test_identity\"],\n",
    "                            on='TransactionID') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_dict = {}\n",
    "dataframe_dict[\"train\"] = dataframe_train\n",
    "dataframe_dict[\"test\"] = dataframe_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can come back to the flow by using one command only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>387</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>434</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train  test\n",
       "column type                     \n",
       "categorical_integer    387   387\n",
       "categorical_string      23    23\n",
       "continuous              16    15\n",
       "date                     8     8\n",
       "json                     0     0\n",
       "other                    0     0\n",
       "total amount           434   433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "It seems that the next step is not defined. Error'8'\n"
     ]
    }
   ],
   "source": [
    "columns_set = flow.update_data_summary(dataframe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reference dataframe is: train\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in ProductCD feature is: 4\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in ProductCD feature is: 4\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in card4 feature is: 4\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in card4 feature is: 4\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in card6 feature is: 2\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in card6 feature is: 2\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in P_emaildomain feature is: 27\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in P_emaildomain feature is: 27\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in R_emaildomain feature is: 31\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in R_emaildomain feature is: 31\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in M4 feature is: 4\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in M4 feature is: 4\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in id_12 feature is: 2\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in id_12 feature is: 2\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in id_15 feature is: 4\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in id_15 feature is: 4\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in id_16 feature is: 3\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in id_16 feature is: 3\n",
      "there are 2 datasets provided\n",
      "encoding the feature in the dataset train\n",
      "the number of classes in id_23 feature is: 3\n",
      "encoding the feature in the dataset test\n",
      "the number of classes in id_23 feature is: 3\n",
      "the value is considered integer\n",
      "Number of unique elements per string column\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>all data sets</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>string columns</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isFraud</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ProductCD</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card3</th>\n",
       "      <td>6</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>card5</th>\n",
       "      <td>24</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_36</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_37</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_38</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceType</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceInfo</th>\n",
       "      <td>54</td>\n",
       "      <td>50.0</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                train  test  all data sets\n",
       "string columns                            \n",
       "isFraud             2   NaN              2\n",
       "ProductCD           4   4.0              4\n",
       "card3               6  16.0             17\n",
       "card4               4   4.0              4\n",
       "card5              24  15.0             25\n",
       "...               ...   ...            ...\n",
       "id_36               3   3.0              3\n",
       "id_37               3   3.0              3\n",
       "id_38               3   3.0              3\n",
       "DeviceType          3   3.0              3\n",
       "DeviceInfo         54  50.0             94\n",
       "\n",
       "[410 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m******************************\u001b[m\n",
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>409</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>434</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train  test\n",
       "column type                     \n",
       "categorical_integer    409   410\n",
       "categorical_string       0     0\n",
       "continuous              17    15\n",
       "date                     8     8\n",
       "json                     0     0\n",
       "other                    0     0\n",
       "total amount           434   433"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "\u001b[1m\u001b[35mApply target-based encoding to the categorical features by applying the following function:\n",
      "\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.features_encoding(\"frequency\", dataframe_dict: dict, reference: str, drop_encoded_features = False)\u001b[m\u001b[m\n",
      "\u001b[35mAn example of the ignore_columns list: \n",
      "\u001b[m\u001b[32m\u001b[40m ignore_columns = ['id', 'target']\n",
      "\u001b[m\n",
      "\u001b[35mAn example of the reference: \n",
      "\u001b[m\u001b[32m\u001b[40m reference = 'train'\n",
      "\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.encode_categorical_feature(dataframe_dict,print_results=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = [\"TransactionID\", \"isFraud\"]\n",
    "reference = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding the column ProductCD based on the value frequency\n",
      "decoding the column card3 based on the value frequency\n",
      "decoding the column card4 based on the value frequency\n",
      "decoding the column card5 based on the value frequency\n",
      "decoding the column card6 based on the value frequency\n",
      "decoding the column addr1 based on the value frequency\n",
      "decoding the column addr2 based on the value frequency\n",
      "decoding the column dist1 based on the value frequency\n",
      "decoding the column dist2 based on the value frequency\n",
      "decoding the column P_emaildomain based on the value frequency\n",
      "decoding the column R_emaildomain based on the value frequency\n",
      "decoding the column C1 based on the value frequency\n",
      "decoding the column C2 based on the value frequency\n",
      "decoding the column C3 based on the value frequency\n",
      "decoding the column C4 based on the value frequency\n",
      "decoding the column C5 based on the value frequency\n",
      "decoding the column C6 based on the value frequency\n",
      "decoding the column C7 based on the value frequency\n",
      "decoding the column C8 based on the value frequency\n",
      "decoding the column C9 based on the value frequency\n",
      "decoding the column C10 based on the value frequency\n",
      "decoding the column C11 based on the value frequency\n",
      "decoding the column C12 based on the value frequency\n",
      "decoding the column C13 based on the value frequency\n",
      "decoding the column C14 based on the value frequency\n",
      "decoding the column D1 based on the value frequency\n",
      "decoding the column D2 based on the value frequency\n",
      "decoding the column D3 based on the value frequency\n",
      "decoding the column D4 based on the value frequency\n",
      "decoding the column D5 based on the value frequency\n",
      "decoding the column D6 based on the value frequency\n",
      "decoding the column D7 based on the value frequency\n",
      "decoding the column D9 based on the value frequency\n",
      "decoding the column D10 based on the value frequency\n",
      "decoding the column D11 based on the value frequency\n",
      "decoding the column D12 based on the value frequency\n",
      "decoding the column D13 based on the value frequency\n",
      "decoding the column D14 based on the value frequency\n",
      "decoding the column D15 based on the value frequency\n",
      "decoding the column M4 based on the value frequency\n",
      "decoding the column V1 based on the value frequency\n",
      "decoding the column V2 based on the value frequency\n",
      "decoding the column V3 based on the value frequency\n",
      "decoding the column V4 based on the value frequency\n",
      "decoding the column V5 based on the value frequency\n",
      "decoding the column V6 based on the value frequency\n",
      "decoding the column V7 based on the value frequency\n",
      "decoding the column V8 based on the value frequency\n",
      "decoding the column V9 based on the value frequency\n",
      "decoding the column V10 based on the value frequency\n",
      "decoding the column V11 based on the value frequency\n",
      "decoding the column V12 based on the value frequency\n",
      "decoding the column V13 based on the value frequency\n",
      "decoding the column V14 based on the value frequency\n",
      "decoding the column V15 based on the value frequency\n",
      "decoding the column V16 based on the value frequency\n",
      "decoding the column V17 based on the value frequency\n",
      "decoding the column V18 based on the value frequency\n",
      "decoding the column V19 based on the value frequency\n",
      "decoding the column V20 based on the value frequency\n",
      "decoding the column V21 based on the value frequency\n",
      "decoding the column V22 based on the value frequency\n",
      "decoding the column V23 based on the value frequency\n",
      "decoding the column V24 based on the value frequency\n",
      "decoding the column V25 based on the value frequency\n",
      "decoding the column V26 based on the value frequency\n",
      "decoding the column V27 based on the value frequency\n",
      "decoding the column V28 based on the value frequency\n",
      "decoding the column V29 based on the value frequency\n",
      "decoding the column V30 based on the value frequency\n",
      "decoding the column V31 based on the value frequency\n",
      "decoding the column V32 based on the value frequency\n",
      "decoding the column V33 based on the value frequency\n",
      "decoding the column V34 based on the value frequency\n",
      "decoding the column V35 based on the value frequency\n",
      "decoding the column V36 based on the value frequency\n",
      "decoding the column V37 based on the value frequency\n",
      "decoding the column V38 based on the value frequency\n",
      "decoding the column V39 based on the value frequency\n",
      "decoding the column V40 based on the value frequency\n",
      "decoding the column V41 based on the value frequency\n",
      "decoding the column V42 based on the value frequency\n",
      "decoding the column V43 based on the value frequency\n",
      "decoding the column V44 based on the value frequency\n",
      "decoding the column V45 based on the value frequency\n",
      "decoding the column V46 based on the value frequency\n",
      "decoding the column V47 based on the value frequency\n",
      "decoding the column V48 based on the value frequency\n",
      "decoding the column V49 based on the value frequency\n",
      "decoding the column V50 based on the value frequency\n",
      "decoding the column V51 based on the value frequency\n",
      "decoding the column V52 based on the value frequency\n",
      "decoding the column V53 based on the value frequency\n",
      "decoding the column V54 based on the value frequency\n",
      "decoding the column V55 based on the value frequency\n",
      "decoding the column V56 based on the value frequency\n",
      "decoding the column V57 based on the value frequency\n",
      "decoding the column V58 based on the value frequency\n",
      "decoding the column V59 based on the value frequency\n",
      "decoding the column V60 based on the value frequency\n",
      "decoding the column V61 based on the value frequency\n",
      "decoding the column V62 based on the value frequency\n",
      "decoding the column V63 based on the value frequency\n",
      "decoding the column V64 based on the value frequency\n",
      "decoding the column V65 based on the value frequency\n",
      "decoding the column V66 based on the value frequency\n",
      "decoding the column V67 based on the value frequency\n",
      "decoding the column V68 based on the value frequency\n",
      "decoding the column V69 based on the value frequency\n",
      "decoding the column V70 based on the value frequency\n",
      "decoding the column V71 based on the value frequency\n",
      "decoding the column V72 based on the value frequency\n",
      "decoding the column V73 based on the value frequency\n",
      "decoding the column V74 based on the value frequency\n",
      "decoding the column V75 based on the value frequency\n",
      "decoding the column V76 based on the value frequency\n",
      "decoding the column V77 based on the value frequency\n",
      "decoding the column V78 based on the value frequency\n",
      "decoding the column V79 based on the value frequency\n",
      "decoding the column V80 based on the value frequency\n",
      "decoding the column V81 based on the value frequency\n",
      "decoding the column V82 based on the value frequency\n",
      "decoding the column V83 based on the value frequency\n",
      "decoding the column V84 based on the value frequency\n",
      "decoding the column V85 based on the value frequency\n",
      "decoding the column V86 based on the value frequency\n",
      "decoding the column V87 based on the value frequency\n",
      "decoding the column V88 based on the value frequency\n",
      "decoding the column V89 based on the value frequency\n",
      "decoding the column V90 based on the value frequency\n",
      "decoding the column V91 based on the value frequency\n",
      "decoding the column V92 based on the value frequency\n",
      "decoding the column V93 based on the value frequency\n",
      "decoding the column V94 based on the value frequency\n",
      "decoding the column V95 based on the value frequency\n",
      "decoding the column V96 based on the value frequency\n",
      "decoding the column V97 based on the value frequency\n",
      "decoding the column V98 based on the value frequency\n",
      "decoding the column V99 based on the value frequency\n",
      "decoding the column V100 based on the value frequency\n",
      "decoding the column V101 based on the value frequency\n",
      "decoding the column V102 based on the value frequency\n",
      "decoding the column V103 based on the value frequency\n",
      "decoding the column V104 based on the value frequency\n",
      "decoding the column V105 based on the value frequency\n",
      "decoding the column V106 based on the value frequency\n",
      "decoding the column V107 based on the value frequency\n",
      "decoding the column V108 based on the value frequency\n",
      "decoding the column V109 based on the value frequency\n",
      "decoding the column V110 based on the value frequency\n",
      "decoding the column V111 based on the value frequency\n",
      "decoding the column V112 based on the value frequency\n",
      "decoding the column V113 based on the value frequency\n",
      "decoding the column V114 based on the value frequency\n",
      "decoding the column V115 based on the value frequency\n",
      "decoding the column V116 based on the value frequency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding the column V117 based on the value frequency\n",
      "decoding the column V118 based on the value frequency\n",
      "decoding the column V119 based on the value frequency\n",
      "decoding the column V120 based on the value frequency\n",
      "decoding the column V121 based on the value frequency\n",
      "decoding the column V122 based on the value frequency\n",
      "decoding the column V123 based on the value frequency\n",
      "decoding the column V124 based on the value frequency\n",
      "decoding the column V125 based on the value frequency\n",
      "decoding the column V126 based on the value frequency\n",
      "decoding the column V127 based on the value frequency\n",
      "decoding the column V128 based on the value frequency\n",
      "decoding the column V129 based on the value frequency\n",
      "decoding the column V130 based on the value frequency\n",
      "decoding the column V131 based on the value frequency\n",
      "decoding the column V132 based on the value frequency\n",
      "decoding the column V133 based on the value frequency\n",
      "decoding the column V134 based on the value frequency\n",
      "decoding the column V135 based on the value frequency\n",
      "decoding the column V136 based on the value frequency\n",
      "decoding the column V137 based on the value frequency\n",
      "decoding the column V138 based on the value frequency\n",
      "decoding the column V139 based on the value frequency\n",
      "decoding the column V140 based on the value frequency\n",
      "decoding the column V141 based on the value frequency\n",
      "decoding the column V142 based on the value frequency\n",
      "decoding the column V143 based on the value frequency\n",
      "decoding the column V144 based on the value frequency\n",
      "decoding the column V145 based on the value frequency\n",
      "decoding the column V146 based on the value frequency\n",
      "decoding the column V147 based on the value frequency\n",
      "decoding the column V148 based on the value frequency\n",
      "decoding the column V149 based on the value frequency\n",
      "decoding the column V150 based on the value frequency\n",
      "decoding the column V151 based on the value frequency\n",
      "decoding the column V152 based on the value frequency\n",
      "decoding the column V153 based on the value frequency\n",
      "decoding the column V154 based on the value frequency\n",
      "decoding the column V155 based on the value frequency\n",
      "decoding the column V156 based on the value frequency\n",
      "decoding the column V157 based on the value frequency\n",
      "decoding the column V158 based on the value frequency\n",
      "decoding the column V161 based on the value frequency\n",
      "decoding the column V162 based on the value frequency\n",
      "decoding the column V163 based on the value frequency\n",
      "decoding the column V164 based on the value frequency\n",
      "decoding the column V165 based on the value frequency\n",
      "decoding the column V166 based on the value frequency\n",
      "decoding the column V167 based on the value frequency\n",
      "decoding the column V168 based on the value frequency\n",
      "decoding the column V169 based on the value frequency\n",
      "decoding the column V170 based on the value frequency\n",
      "decoding the column V171 based on the value frequency\n",
      "decoding the column V172 based on the value frequency\n",
      "decoding the column V173 based on the value frequency\n",
      "decoding the column V174 based on the value frequency\n",
      "decoding the column V175 based on the value frequency\n",
      "decoding the column V176 based on the value frequency\n",
      "decoding the column V177 based on the value frequency\n",
      "decoding the column V178 based on the value frequency\n",
      "decoding the column V179 based on the value frequency\n",
      "decoding the column V180 based on the value frequency\n",
      "decoding the column V181 based on the value frequency\n",
      "decoding the column V182 based on the value frequency\n",
      "decoding the column V183 based on the value frequency\n",
      "decoding the column V184 based on the value frequency\n",
      "decoding the column V185 based on the value frequency\n",
      "decoding the column V186 based on the value frequency\n",
      "decoding the column V187 based on the value frequency\n",
      "decoding the column V188 based on the value frequency\n",
      "decoding the column V189 based on the value frequency\n",
      "decoding the column V190 based on the value frequency\n",
      "decoding the column V191 based on the value frequency\n",
      "decoding the column V192 based on the value frequency\n",
      "decoding the column V193 based on the value frequency\n",
      "decoding the column V194 based on the value frequency\n",
      "decoding the column V195 based on the value frequency\n",
      "decoding the column V196 based on the value frequency\n",
      "decoding the column V197 based on the value frequency\n",
      "decoding the column V198 based on the value frequency\n",
      "decoding the column V199 based on the value frequency\n",
      "decoding the column V200 based on the value frequency\n",
      "decoding the column V201 based on the value frequency\n",
      "decoding the column V202 based on the value frequency\n",
      "decoding the column V205 based on the value frequency\n",
      "decoding the column V206 based on the value frequency\n",
      "decoding the column V207 based on the value frequency\n",
      "decoding the column V208 based on the value frequency\n",
      "decoding the column V209 based on the value frequency\n",
      "decoding the column V210 based on the value frequency\n",
      "decoding the column V211 based on the value frequency\n",
      "decoding the column V212 based on the value frequency\n",
      "decoding the column V213 based on the value frequency\n",
      "decoding the column V214 based on the value frequency\n",
      "decoding the column V215 based on the value frequency\n",
      "decoding the column V216 based on the value frequency\n",
      "decoding the column V217 based on the value frequency\n",
      "decoding the column V218 based on the value frequency\n",
      "decoding the column V219 based on the value frequency\n",
      "decoding the column V220 based on the value frequency\n",
      "decoding the column V221 based on the value frequency\n",
      "decoding the column V222 based on the value frequency\n",
      "decoding the column V223 based on the value frequency\n",
      "decoding the column V224 based on the value frequency\n",
      "decoding the column V225 based on the value frequency\n",
      "decoding the column V226 based on the value frequency\n",
      "decoding the column V227 based on the value frequency\n",
      "decoding the column V228 based on the value frequency\n",
      "decoding the column V229 based on the value frequency\n",
      "decoding the column V230 based on the value frequency\n",
      "decoding the column V231 based on the value frequency\n",
      "decoding the column V232 based on the value frequency\n",
      "decoding the column V233 based on the value frequency\n",
      "decoding the column V234 based on the value frequency\n",
      "decoding the column V235 based on the value frequency\n",
      "decoding the column V236 based on the value frequency\n",
      "decoding the column V237 based on the value frequency\n",
      "decoding the column V238 based on the value frequency\n",
      "decoding the column V239 based on the value frequency\n",
      "decoding the column V240 based on the value frequency\n",
      "decoding the column V241 based on the value frequency\n",
      "decoding the column V242 based on the value frequency\n",
      "decoding the column V243 based on the value frequency\n",
      "decoding the column V244 based on the value frequency\n",
      "decoding the column V245 based on the value frequency\n",
      "decoding the column V246 based on the value frequency\n",
      "decoding the column V247 based on the value frequency\n",
      "decoding the column V248 based on the value frequency\n",
      "decoding the column V249 based on the value frequency\n",
      "decoding the column V250 based on the value frequency\n",
      "decoding the column V251 based on the value frequency\n",
      "decoding the column V252 based on the value frequency\n",
      "decoding the column V253 based on the value frequency\n",
      "decoding the column V254 based on the value frequency\n",
      "decoding the column V255 based on the value frequency\n",
      "decoding the column V256 based on the value frequency\n",
      "decoding the column V257 based on the value frequency\n",
      "decoding the column V258 based on the value frequency\n",
      "decoding the column V259 based on the value frequency\n",
      "decoding the column V260 based on the value frequency\n",
      "decoding the column V261 based on the value frequency\n",
      "decoding the column V262 based on the value frequency\n",
      "decoding the column V263 based on the value frequency\n",
      "decoding the column V266 based on the value frequency\n",
      "decoding the column V267 based on the value frequency\n",
      "decoding the column V268 based on the value frequency\n",
      "decoding the column V269 based on the value frequency\n",
      "decoding the column V270 based on the value frequency\n",
      "decoding the column V271 based on the value frequency\n",
      "decoding the column V272 based on the value frequency\n",
      "decoding the column V273 based on the value frequency\n",
      "decoding the column V274 based on the value frequency\n",
      "decoding the column V275 based on the value frequency\n",
      "decoding the column V276 based on the value frequency\n",
      "decoding the column V277 based on the value frequency\n",
      "decoding the column V278 based on the value frequency\n",
      "decoding the column V279 based on the value frequency\n",
      "decoding the column V280 based on the value frequency\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoding the column V281 based on the value frequency\n",
      "decoding the column V282 based on the value frequency\n",
      "decoding the column V283 based on the value frequency\n",
      "decoding the column V284 based on the value frequency\n",
      "decoding the column V285 based on the value frequency\n",
      "decoding the column V286 based on the value frequency\n",
      "decoding the column V287 based on the value frequency\n",
      "decoding the column V288 based on the value frequency\n",
      "decoding the column V289 based on the value frequency\n",
      "decoding the column V290 based on the value frequency\n",
      "decoding the column V291 based on the value frequency\n",
      "decoding the column V292 based on the value frequency\n",
      "decoding the column V293 based on the value frequency\n",
      "decoding the column V294 based on the value frequency\n",
      "decoding the column V295 based on the value frequency\n",
      "decoding the column V296 based on the value frequency\n",
      "decoding the column V297 based on the value frequency\n",
      "decoding the column V298 based on the value frequency\n",
      "decoding the column V299 based on the value frequency\n",
      "decoding the column V300 based on the value frequency\n",
      "decoding the column V301 based on the value frequency\n",
      "decoding the column V302 based on the value frequency\n",
      "decoding the column V303 based on the value frequency\n",
      "decoding the column V304 based on the value frequency\n",
      "decoding the column V305 based on the value frequency\n",
      "decoding the column V306 based on the value frequency\n",
      "decoding the column V308 based on the value frequency\n",
      "decoding the column V309 based on the value frequency\n",
      "decoding the column V310 based on the value frequency\n",
      "decoding the column V311 based on the value frequency\n",
      "decoding the column V312 based on the value frequency\n",
      "decoding the column V313 based on the value frequency\n",
      "decoding the column V314 based on the value frequency\n",
      "decoding the column V315 based on the value frequency\n",
      "decoding the column V316 based on the value frequency\n",
      "decoding the column V317 based on the value frequency\n",
      "decoding the column V318 based on the value frequency\n",
      "decoding the column V319 based on the value frequency\n",
      "decoding the column V320 based on the value frequency\n",
      "decoding the column V321 based on the value frequency\n",
      "decoding the column V322 based on the value frequency\n",
      "decoding the column V323 based on the value frequency\n",
      "decoding the column V324 based on the value frequency\n",
      "decoding the column V325 based on the value frequency\n",
      "decoding the column V326 based on the value frequency\n",
      "decoding the column V327 based on the value frequency\n",
      "decoding the column V328 based on the value frequency\n",
      "decoding the column V329 based on the value frequency\n",
      "decoding the column V330 based on the value frequency\n",
      "decoding the column V331 based on the value frequency\n",
      "decoding the column V332 based on the value frequency\n",
      "decoding the column V333 based on the value frequency\n",
      "decoding the column V334 based on the value frequency\n",
      "decoding the column V335 based on the value frequency\n",
      "decoding the column V336 based on the value frequency\n",
      "decoding the column V337 based on the value frequency\n",
      "decoding the column V338 based on the value frequency\n",
      "decoding the column V339 based on the value frequency\n",
      "decoding the column id_01 based on the value frequency\n",
      "decoding the column id_03 based on the value frequency\n",
      "decoding the column id_04 based on the value frequency\n",
      "decoding the column id_05 based on the value frequency\n",
      "decoding the column id_06 based on the value frequency\n",
      "decoding the column id_07 based on the value frequency\n",
      "decoding the column id_08 based on the value frequency\n",
      "decoding the column id_09 based on the value frequency\n",
      "decoding the column id_10 based on the value frequency\n",
      "decoding the column id_11 based on the value frequency\n",
      "decoding the column id_12 based on the value frequency\n",
      "decoding the column id_13 based on the value frequency\n",
      "decoding the column id_14 based on the value frequency\n",
      "decoding the column id_15 based on the value frequency\n",
      "decoding the column id_16 based on the value frequency\n",
      "decoding the column id_17 based on the value frequency\n",
      "decoding the column id_18 based on the value frequency\n",
      "decoding the column id_21 based on the value frequency\n",
      "decoding the column id_22 based on the value frequency\n",
      "decoding the column id_23 based on the value frequency\n",
      "decoding the column id_24 based on the value frequency\n",
      "decoding the column id_25 based on the value frequency\n",
      "decoding the column id_26 based on the value frequency\n",
      "decoding the column id_27 based on the value frequency\n",
      "decoding the column id_28 based on the value frequency\n",
      "decoding the column id_29 based on the value frequency\n",
      "decoding the column id_30 based on the value frequency\n",
      "decoding the column id_31 based on the value frequency\n",
      "decoding the column id_32 based on the value frequency\n",
      "decoding the column id_33 based on the value frequency\n",
      "decoding the column id_34 based on the value frequency\n",
      "decoding the column id_35 based on the value frequency\n",
      "decoding the column id_36 based on the value frequency\n",
      "decoding the column id_37 based on the value frequency\n",
      "decoding the column id_38 based on the value frequency\n",
      "decoding the column DeviceType based on the value frequency\n",
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>817</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>842</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train  test\n",
       "column type                     \n",
       "categorical_integer    817   818\n",
       "categorical_string       0     0\n",
       "continuous              17    15\n",
       "date                     8     8\n",
       "json                     0     0\n",
       "other                    0     0\n",
       "total amount           842   841"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "\u001b[1m\u001b[35mIf some features have in all rows the same value, they have no influence on the target prediction. It is a good idea to delete such features:\n",
      "\u001b[m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.drop_columns_constant_values(dataframe_dict: dict, ignore_columns: list)\u001b[m\u001b[35mAn example of the ignore_columns list: \n",
      "\u001b[m\u001b[32m\u001b[40m ignore_columns = [target]\n",
      "\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.features_encoding(\"frequency\",\n",
    "                                                     dataframe_dict,\n",
    "                                                     reference=reference,\n",
    "                                                     ignore_columns=ignore_columns,\n",
    "                                                     drop_encoded_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = ['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist1 1\n",
      "C5 1\n",
      "C9 1\n",
      "D11 1\n",
      "M1 0\n",
      "M2 0\n",
      "M3 0\n",
      "M5 0\n",
      "M6 0\n",
      "M7 0\n",
      "M8 0\n",
      "M9 0\n",
      "V1 1\n",
      "V2 1\n",
      "V3 1\n",
      "V4 1\n",
      "V5 1\n",
      "V6 1\n",
      "V7 1\n",
      "V8 1\n",
      "V9 1\n",
      "V10 1\n",
      "V11 1\n",
      "V107 1\n",
      "V108 1\n",
      "V111 1\n",
      "V112 1\n",
      "V113 1\n",
      "V117 1\n",
      "V118 1\n",
      "V119 1\n",
      "V305 1\n",
      "dist1_frequency_encoding 1\n",
      "C5_frequency_encoding 1\n",
      "C9_frequency_encoding 1\n",
      "D11_frequency_encoding 1\n",
      "V1_frequency_encoding 1\n",
      "V2_frequency_encoding 1\n",
      "V3_frequency_encoding 1\n",
      "V4_frequency_encoding 1\n",
      "V5_frequency_encoding 1\n",
      "V6_frequency_encoding 1\n",
      "V7_frequency_encoding 1\n",
      "V8_frequency_encoding 1\n",
      "V9_frequency_encoding 1\n",
      "V10_frequency_encoding 1\n",
      "V11_frequency_encoding 1\n",
      "V75_frequency_encoding 1\n",
      "V76_frequency_encoding 1\n",
      "V89_frequency_encoding 1\n",
      "V90_frequency_encoding 1\n",
      "V91_frequency_encoding 1\n",
      "V107_frequency_encoding 1\n",
      "V108_frequency_encoding 1\n",
      "V111_frequency_encoding 1\n",
      "V112_frequency_encoding 1\n",
      "V113_frequency_encoding 1\n",
      "V117_frequency_encoding 1\n",
      "V118_frequency_encoding 1\n",
      "V119_frequency_encoding 1\n",
      "V305_frequency_encoding 1\n",
      "Constant columns count: 61\n",
      "842 columns total\n",
      "781 columns left\n",
      "The set of remaining columns should be modified. Error: \"['isFraud'] not in index\"\n",
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>764</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>781</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train  test\n",
       "column type                     \n",
       "categorical_integer    764   765\n",
       "categorical_string       0     0\n",
       "continuous              17    15\n",
       "date                     0     0\n",
       "json                     0     0\n",
       "other                    0     0\n",
       "total amount           781   780"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "\u001b[1m\u001b[35mIf some features are highly correlated, they do not provide more information about the target prediction. It is a good idea to drop such features but keep one:\n",
      "\u001b[m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.drop_correlated_columns(dataframe_dict: dict, ignore_columns: list)\u001b[m\u001b[35mAn example of the ignore_columns list: \n",
      "\u001b[m\u001b[32m\u001b[40m ignore_columns = [target]\n",
      "\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.drop_columns_constant_values(dataframe_dict, ignore_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with correlations more than 0.98 :\n",
      "card6-->card6_frequency_encoding: r^2=0.9999999999999928\n",
      "addr2-->V138: r^2=0.9868330484711274\n",
      "addr2-->V141: r^2=0.9864418939379327\n",
      "addr2-->V142: r^2=0.9831351542113818\n",
      "addr2-->V147: r^2=0.9840940762475665\n",
      "addr2-->V149: r^2=0.9831750487283971\n",
      "addr2-->V156: r^2=0.9843199897805834\n",
      "addr2-->V158: r^2=0.984157605961662\n",
      "addr2-->V161: r^2=0.9821783080541412\n",
      "addr2-->V162: r^2=0.9810028197721269\n",
      "addr2-->V163: r^2=0.9824613760842971\n",
      "addr2-->V325: r^2=0.9871189029695654\n",
      "addr2-->V327: r^2=0.9872002927162583\n",
      "addr2-->V334: r^2=0.9806578067911772\n",
      "addr2-->addr1_frequency_encoding: r^2=0.991128796799192\n",
      "D10-->V12: r^2=0.9925706634641449\n",
      "D10-->V13: r^2=0.9925706634641449\n",
      "D10-->V14: r^2=0.9871370342388076\n",
      "D10-->V17: r^2=0.991259847121874\n",
      "D10-->V18: r^2=0.991259847121874\n",
      "D10-->V21: r^2=0.9803041753496845\n",
      "D10-->V22: r^2=0.9873277612187439\n",
      "D10-->V23: r^2=0.9901769395839428\n",
      "D10-->V24: r^2=0.9901769395839428\n",
      "D10-->V25: r^2=0.9871370342388076\n",
      "D10-->V26: r^2=0.9912279778146676\n",
      "D10-->V27: r^2=0.9925706634641449\n",
      "D10-->V28: r^2=0.9925706634641449\n",
      "D10-->V29: r^2=0.9925706634641449\n",
      "D10-->V30: r^2=0.9925706634641449\n",
      "D10-->V31: r^2=0.9807728343047994\n",
      "D10-->V32: r^2=0.9807728343047994\n",
      "D10-->V12_frequency_encoding: r^2=0.9925706634641467\n",
      "D10-->V13_frequency_encoding: r^2=0.9925706634641467\n",
      "D10-->V27_frequency_encoding: r^2=0.9925706634641467\n",
      "D10-->V28_frequency_encoding: r^2=0.9925706634641467\n",
      "D10-->V29_frequency_encoding: r^2=0.9925706634641467\n",
      "D10-->V30_frequency_encoding: r^2=0.9925706634641467\n",
      "V12-->D10: r^2=0.9925706634641449\n",
      "V12-->V15: r^2=0.9815496516554788\n",
      "V12-->V16: r^2=0.9815496516554788\n",
      "V12-->V19: r^2=0.9945591462020144\n",
      "V12-->V20: r^2=0.9945591462020144\n",
      "V15-->V33: r^2=0.9865283644655022\n",
      "V15-->V34: r^2=0.9865283644655022\n",
      "V35-->V36: r^2=1.0\n",
      "V35-->V37: r^2=0.988148150178822\n",
      "V35-->V38: r^2=0.9830515881952422\n",
      "V35-->V39: r^2=0.9960732568697264\n",
      "V35-->V40: r^2=0.9949707338210365\n",
      "V35-->V41: r^2=1.0\n",
      "V35-->V42: r^2=0.9846106910180712\n",
      "V35-->V43: r^2=0.9891620017024114\n",
      "V35-->V44: r^2=0.990654442071352\n",
      "V35-->V45: r^2=0.990654442071352\n",
      "V35-->V46: r^2=0.9914642901284079\n",
      "V35-->V47: r^2=0.9914642901284079\n",
      "V35-->V48: r^2=1.0\n",
      "V35-->V49: r^2=1.0\n",
      "V35-->V35_frequency_encoding: r^2=1.000000000000005\n",
      "V35-->V36_frequency_encoding: r^2=1.000000000000005\n",
      "V35-->V41_frequency_encoding: r^2=1.000000000000005\n",
      "V35-->V48_frequency_encoding: r^2=1.000000000000005\n",
      "V35-->V49_frequency_encoding: r^2=1.000000000000005\n",
      "V36-->V35: r^2=1.0\n",
      "V46-->V51: r^2=0.9841851857268552\n",
      "V46-->V52: r^2=0.9841851857268552\n",
      "V53-->V54: r^2=1.0\n",
      "V53-->V56: r^2=0.9836539353741424\n",
      "V53-->V59: r^2=0.9962469278355193\n",
      "V53-->V60: r^2=0.9943295004940917\n",
      "V53-->V61: r^2=0.9857626976086974\n",
      "V53-->V62: r^2=0.9857626976086974\n",
      "V53-->V63: r^2=0.981815512679777\n",
      "V53-->V64: r^2=0.9855376164782077\n",
      "V53-->V65: r^2=0.9943887654176511\n",
      "V53-->V66: r^2=0.9871642102166462\n",
      "V53-->V67: r^2=0.9871642102166462\n",
      "V53-->V68: r^2=1.0\n",
      "V53-->V69: r^2=1.0\n",
      "V53-->V70: r^2=1.0\n",
      "V53-->V53_frequency_encoding: r^2=1.0000000000000022\n",
      "V53-->V54_frequency_encoding: r^2=1.0000000000000022\n",
      "V53-->V68_frequency_encoding: r^2=1.0000000000000022\n",
      "V53-->V69_frequency_encoding: r^2=1.0000000000000022\n",
      "V53-->V70_frequency_encoding: r^2=1.0000000000000022\n",
      "V54-->V53: r^2=1.0\n",
      "V56-->V55: r^2=0.9911136131523437\n",
      "V57-->V58: r^2=1.0\n",
      "V57-->V71: r^2=0.9909472559860949\n",
      "V57-->V72: r^2=0.9909472559860949\n",
      "V57-->V73: r^2=0.9922407603953606\n",
      "V57-->V74: r^2=0.9922407603953606\n",
      "V58-->V57: r^2=1.0\n",
      "V75-->V76: r^2=1.0\n",
      "V75-->V77: r^2=0.9900702429703152\n",
      "V75-->V78: r^2=0.9888866361725286\n",
      "V75-->V79: r^2=0.9844238170848574\n",
      "V75-->V80: r^2=0.9968469223376148\n",
      "V75-->V81: r^2=0.9949554645089848\n",
      "V75-->V82: r^2=0.9906947764648426\n",
      "V75-->V83: r^2=0.9906947764648426\n",
      "V75-->V85: r^2=0.9804367312426129\n",
      "V75-->V86: r^2=0.9878275613216311\n",
      "V75-->V87: r^2=0.9878275613216311\n",
      "V75-->V88: r^2=0.9890762632233955\n",
      "V75-->V89: r^2=1.0\n",
      "V75-->V90: r^2=1.0\n",
      "V75-->V91: r^2=1.0\n",
      "V75-->V92: r^2=0.9890762632233974\n",
      "V75-->V93: r^2=0.9883916314407961\n",
      "V76-->V75: r^2=1.0\n",
      "V80-->V84: r^2=0.9897962899733402\n",
      "V101-->V102: r^2=1.0\n",
      "V101-->V103: r^2=1.0\n",
      "V102-->V101: r^2=1.0\n",
      "V104-->V106: r^2=0.9967626151927019\n",
      "V106-->V104: r^2=0.9967626151927019\n",
      "V109-->V110: r^2=1.0\n",
      "V110-->V109: r^2=1.0\n",
      "V114-->V120: r^2=1.0\n",
      "V114-->V121: r^2=1.0\n",
      "V114-->V122: r^2=1.0\n",
      "V115-->V116: r^2=1.0\n",
      "V116-->V115: r^2=1.0\n",
      "V120-->V114: r^2=1.0\n",
      "V132-->V133: r^2=1.0\n",
      "V132-->V134: r^2=1.0\n",
      "V133-->V132: r^2=1.0\n",
      "V135-->V137: r^2=0.9991756651216334\n",
      "V137-->V135: r^2=0.9991756651216334\n",
      "V138-->addr2: r^2=0.9868330484711274\n",
      "V138-->V146: r^2=0.9840905782556938\n",
      "V138-->V324: r^2=0.9800564715447201\n",
      "V138-->V336: r^2=0.980487378791698\n",
      "V139-->V140: r^2=0.9912192942143403\n",
      "V139-->V148: r^2=0.98630876820771\n",
      "V139-->V153: r^2=0.98630876820771\n",
      "V139-->V154: r^2=0.9885136977989183\n",
      "V139-->V155: r^2=0.986496518235153\n",
      "V139-->V157: r^2=0.9882546897028726\n",
      "V140-->V139: r^2=0.9912192942143403\n",
      "V142-->V326: r^2=0.9831978772251481\n",
      "V144-->V145: r^2=0.98895426654829\n",
      "V145-->V144: r^2=0.98895426654829\n",
      "V146-->V328: r^2=0.9813855300741436\n",
      "V146-->V330: r^2=0.9812909398010834\n",
      "V147-->V322: r^2=0.9815208349345474\n",
      "V147-->V329: r^2=0.9815067255530038\n",
      "V152-->V159: r^2=0.9956763214995289\n",
      "V152-->V160: r^2=0.9962033769671493\n",
      "V159-->V152: r^2=0.9956763214995289\n",
      "V164-->V165: r^2=0.990373951110197\n",
      "V165-->V164: r^2=0.990373951110197\n",
      "V169-->V174: r^2=0.9808441747910789\n",
      "V169-->V176: r^2=0.985989136770171\n",
      "V170-->V171: r^2=0.9812607271381298\n",
      "V171-->V170: r^2=0.9812607271381298\n",
      "V172-->V173: r^2=0.991388125852246\n",
      "V173-->V172: r^2=0.991388125852246\n",
      "V174-->V169: r^2=0.9808441747910789\n",
      "V174-->V175: r^2=0.9906050753238468\n",
      "V177-->V193: r^2=0.9819653843486834\n",
      "V180-->V182: r^2=0.9917370431534224\n",
      "V181-->V183: r^2=0.9945413720735604\n",
      "V182-->V180: r^2=0.9917370431534224\n",
      "V183-->V181: r^2=0.9945413720735604\n",
      "V184-->V185: r^2=0.9991589679802431\n",
      "V185-->V184: r^2=0.9991589679802431\n",
      "V186-->V187: r^2=0.9848819139940793\n",
      "V186-->V190: r^2=0.9917438679370487\n",
      "V186-->V191: r^2=0.9899836123719934\n",
      "V186-->V196: r^2=0.988707411439959\n",
      "V187-->V186: r^2=0.9848819139940793\n",
      "V188-->V189: r^2=0.9957543863772605\n",
      "V188-->V194: r^2=0.9937201554949453\n",
      "V188-->V195: r^2=0.9924794899400841\n",
      "V188-->V197: r^2=0.9911191220988219\n",
      "V188-->V198: r^2=0.9848383580531475\n",
      "V188-->V200: r^2=0.9818939923299239\n",
      "V189-->V188: r^2=0.9957543863772605\n",
      "V190-->V199: r^2=0.9864231134170971\n",
      "V191-->V192: r^2=0.9925586439249492\n",
      "V193-->V177: r^2=0.9819653843486834\n",
      "V200-->V201: r^2=0.9922420950911925\n",
      "V208-->V209: r^2=0.9888599074125376\n",
      "V208-->V210: r^2=0.9942726665760352\n",
      "V209-->V208: r^2=0.9888599074125376\n",
      "V211-->V212: r^2=0.9863650912675734\n",
      "V211-->V213: r^2=0.9946107580185737\n",
      "V212-->V211: r^2=0.9863650912675734\n",
      "V214-->V216: r^2=0.9939521315619746\n",
      "V216-->V214: r^2=0.9939521315619746\n",
      "V217-->V219: r^2=0.9854991781642882\n",
      "V219-->V217: r^2=0.9854991781642882\n",
      "V221-->V222: r^2=0.9826665920343896\n",
      "V222-->V221: r^2=0.9826665920343896\n",
      "V223-->V225: r^2=0.9967961367170207\n",
      "V223-->V230: r^2=0.9808232227623053\n",
      "V225-->V223: r^2=0.9967961367170207\n",
      "V230-->V228: r^2=0.9894327033255832\n",
      "V235-->V237: r^2=0.9837040599667799\n",
      "V235-->V238: r^2=0.9898505169946352\n",
      "V235-->V239: r^2=0.9889447211234911\n",
      "V237-->V235: r^2=0.9837040599667799\n",
      "V240-->V241: r^2=0.9869960534691488\n",
      "V241-->V240: r^2=0.9869960534691488\n",
      "V242-->V243: r^2=0.9947909408541341\n",
      "V242-->V244: r^2=1.0\n",
      "V242-->V246: r^2=0.9959962905726287\n",
      "V242-->V247: r^2=0.9944149536015106\n",
      "V242-->V248: r^2=0.9858891985030916\n",
      "V242-->V252: r^2=0.9938895580641521\n",
      "V242-->V254: r^2=0.9879629658470608\n",
      "V242-->V257: r^2=0.9901660803063927\n",
      "V242-->V258: r^2=0.9888335157414062\n",
      "V243-->V242: r^2=0.9947909408541341\n",
      "V245-->V255: r^2=0.981293891639227\n",
      "V247-->V249: r^2=0.9860669837180188\n",
      "V250-->V251: r^2=1.0\n",
      "V251-->V250: r^2=1.0\n",
      "V255-->V245: r^2=0.981293891639227\n",
      "V255-->V256: r^2=0.9936591694416321\n",
      "V264-->V265: r^2=0.9997120904579753\n",
      "V265-->V264: r^2=0.9997120904579753\n",
      "V271-->V272: r^2=0.9986000252199526\n",
      "V272-->V271: r^2=0.9986000252199526\n",
      "V297-->V299: r^2=1.0\n",
      "V299-->V297: r^2=1.0\n",
      "V300-->V301: r^2=1.0\n",
      "V301-->V300: r^2=1.0\n",
      "V319-->V321: r^2=0.999106836009038\n",
      "V321-->V319: r^2=0.999106836009038\n",
      "V322-->V323: r^2=0.983732738028885\n",
      "V331-->V332: r^2=0.985425897007144\n",
      "V331-->V333: r^2=0.9946883191212063\n",
      "V331-->V337: r^2=0.9822082514601943\n",
      "V331-->V339: r^2=0.9820638728731871\n",
      "V332-->V331: r^2=0.985425897007144\n",
      "V336-->V335: r^2=0.9873799857466108\n",
      "V337-->V338: r^2=0.9867615150566338\n",
      "id_03-->id_04: r^2=0.9914348659803544\n",
      "id_03-->id_04_frequency_encoding: r^2=0.9914348659803559\n",
      "id_04-->id_03: r^2=0.9914348659803544\n",
      "id_09-->id_10: r^2=0.9837791484498742\n",
      "id_09-->D9_frequency_encoding: r^2=0.9857037413288214\n",
      "id_10-->id_09: r^2=0.9837791484498742\n",
      "id_12-->id_12_frequency_encoding: r^2=0.9999999999999928\n",
      "id_21-->id_24: r^2=0.9836090955099258\n",
      "id_24-->id_21: r^2=0.9836090955099258\n",
      "id_27-->id_07_frequency_encoding: r^2=0.9999989566501299\n",
      "id_27-->id_08_frequency_encoding: r^2=0.9999989566501299\n",
      "id_27-->id_21_frequency_encoding: r^2=0.9999993028012301\n",
      "id_27-->id_22_frequency_encoding: r^2=0.99999894928101\n",
      "id_27-->id_23_frequency_encoding: r^2=0.9999989492810069\n",
      "id_27-->id_24_frequency_encoding: r^2=0.9999989492810069\n",
      "id_27-->id_25_frequency_encoding: r^2=0.9999993028012301\n",
      "id_27-->id_26_frequency_encoding: r^2=0.9999989566501299\n",
      "id_27-->id_27_frequency_encoding: r^2=1.0000000000000022\n",
      "id_34-->id_34_frequency_encoding: r^2=0.9852586415863963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card6_frequency_encoding-->card6: r^2=0.9999999999999928\n",
      "V14_frequency_encoding-->V25_frequency_encoding: r^2=1.0\n",
      "V14_frequency_encoding-->V26_frequency_encoding: r^2=1.0\n",
      "V15_frequency_encoding-->V16_frequency_encoding: r^2=1.0\n",
      "V15_frequency_encoding-->V33_frequency_encoding: r^2=1.0\n",
      "V15_frequency_encoding-->V34_frequency_encoding: r^2=1.0\n",
      "V16_frequency_encoding-->V15_frequency_encoding: r^2=1.0\n",
      "V17_frequency_encoding-->V18_frequency_encoding: r^2=1.0\n",
      "V18_frequency_encoding-->V17_frequency_encoding: r^2=1.0\n",
      "V19_frequency_encoding-->V20_frequency_encoding: r^2=1.0\n",
      "V20_frequency_encoding-->V19_frequency_encoding: r^2=1.0\n",
      "V21_frequency_encoding-->V22_frequency_encoding: r^2=1.0\n",
      "V22_frequency_encoding-->V21_frequency_encoding: r^2=1.0\n",
      "V23_frequency_encoding-->V24_frequency_encoding: r^2=1.0\n",
      "V24_frequency_encoding-->V23_frequency_encoding: r^2=1.0\n",
      "V25_frequency_encoding-->V14_frequency_encoding: r^2=1.0\n",
      "V31_frequency_encoding-->V32_frequency_encoding: r^2=1.0\n",
      "V32_frequency_encoding-->V31_frequency_encoding: r^2=1.0\n",
      "V44_frequency_encoding-->V45_frequency_encoding: r^2=1.0\n",
      "V45_frequency_encoding-->V44_frequency_encoding: r^2=1.0\n",
      "V46_frequency_encoding-->V47_frequency_encoding: r^2=1.0\n",
      "V47_frequency_encoding-->V46_frequency_encoding: r^2=1.0\n",
      "V51_frequency_encoding-->V52_frequency_encoding: r^2=1.0\n",
      "V52_frequency_encoding-->V51_frequency_encoding: r^2=1.0\n",
      "V57_frequency_encoding-->V58_frequency_encoding: r^2=1.0\n",
      "V58_frequency_encoding-->V57_frequency_encoding: r^2=1.0\n",
      "V61_frequency_encoding-->V62_frequency_encoding: r^2=1.0\n",
      "V62_frequency_encoding-->V61_frequency_encoding: r^2=1.0\n",
      "V66_frequency_encoding-->V67_frequency_encoding: r^2=1.0\n",
      "V67_frequency_encoding-->V66_frequency_encoding: r^2=1.0\n",
      "V71_frequency_encoding-->V72_frequency_encoding: r^2=1.0\n",
      "V72_frequency_encoding-->V71_frequency_encoding: r^2=1.0\n",
      "V73_frequency_encoding-->V74_frequency_encoding: r^2=1.0\n",
      "V74_frequency_encoding-->V73_frequency_encoding: r^2=1.0\n",
      "V82_frequency_encoding-->V83_frequency_encoding: r^2=1.0\n",
      "V83_frequency_encoding-->V82_frequency_encoding: r^2=1.0\n",
      "V86_frequency_encoding-->V87_frequency_encoding: r^2=1.0\n",
      "V87_frequency_encoding-->V86_frequency_encoding: r^2=1.0\n",
      "V95_frequency_encoding-->V126_frequency_encoding: r^2=0.9995845750571525\n",
      "V96_frequency_encoding-->V127_frequency_encoding: r^2=0.9992224628766408\n",
      "V97_frequency_encoding-->V128_frequency_encoding: r^2=0.9995617861968574\n",
      "V98_frequency_encoding-->V129_frequency_encoding: r^2=0.999999999999997\n",
      "V99_frequency_encoding-->V130_frequency_encoding: r^2=0.999956269938952\n",
      "V100_frequency_encoding-->V131_frequency_encoding: r^2=0.9999936194330102\n",
      "V101_frequency_encoding-->V102_frequency_encoding: r^2=1.0\n",
      "V101_frequency_encoding-->V103_frequency_encoding: r^2=1.0\n",
      "V101_frequency_encoding-->V132_frequency_encoding: r^2=0.999976419929593\n",
      "V101_frequency_encoding-->V133_frequency_encoding: r^2=0.999976419929593\n",
      "V101_frequency_encoding-->V134_frequency_encoding: r^2=0.999976419929593\n",
      "V102_frequency_encoding-->V101_frequency_encoding: r^2=1.0\n",
      "V104_frequency_encoding-->V135_frequency_encoding: r^2=0.9998578481399605\n",
      "V105_frequency_encoding-->V136_frequency_encoding: r^2=0.9997946412185755\n",
      "V106_frequency_encoding-->V137_frequency_encoding: r^2=0.9998293672976326\n",
      "V109_frequency_encoding-->V110_frequency_encoding: r^2=1.0\n",
      "V110_frequency_encoding-->V109_frequency_encoding: r^2=1.0\n",
      "V114_frequency_encoding-->V120_frequency_encoding: r^2=1.0\n",
      "V114_frequency_encoding-->V121_frequency_encoding: r^2=1.0\n",
      "V114_frequency_encoding-->V122_frequency_encoding: r^2=1.0\n",
      "V115_frequency_encoding-->V116_frequency_encoding: r^2=1.0\n",
      "V116_frequency_encoding-->V115_frequency_encoding: r^2=1.0\n",
      "V120_frequency_encoding-->V114_frequency_encoding: r^2=1.0\n",
      "V126_frequency_encoding-->V95_frequency_encoding: r^2=0.9995845750571525\n",
      "V127_frequency_encoding-->V96_frequency_encoding: r^2=0.9992224628766408\n",
      "V128_frequency_encoding-->V97_frequency_encoding: r^2=0.9995617861968574\n",
      "V129_frequency_encoding-->V98_frequency_encoding: r^2=0.999999999999997\n",
      "V130_frequency_encoding-->V99_frequency_encoding: r^2=0.999956269938952\n",
      "V131_frequency_encoding-->V100_frequency_encoding: r^2=0.9999936194330102\n",
      "V135_frequency_encoding-->V104_frequency_encoding: r^2=0.9998578481399605\n",
      "V136_frequency_encoding-->V105_frequency_encoding: r^2=0.9997946412185755\n",
      "V137_frequency_encoding-->V106_frequency_encoding: r^2=0.9998293672976326\n",
      "V139_frequency_encoding-->V140_frequency_encoding: r^2=0.9928236295363644\n",
      "V140_frequency_encoding-->V139_frequency_encoding: r^2=0.9928236295363644\n",
      "V141_frequency_encoding-->V142_frequency_encoding: r^2=0.9999574568156269\n",
      "V141_frequency_encoding-->V161_frequency_encoding: r^2=0.9999315782667743\n",
      "V141_frequency_encoding-->V162_frequency_encoding: r^2=0.9999315782667743\n",
      "V141_frequency_encoding-->V163_frequency_encoding: r^2=0.9999422606014118\n",
      "V142_frequency_encoding-->V141_frequency_encoding: r^2=0.9999574568156269\n",
      "V143_frequency_encoding-->V164_frequency_encoding: r^2=0.9950360464392075\n",
      "V143_frequency_encoding-->V165_frequency_encoding: r^2=0.9952422522899045\n",
      "V144_frequency_encoding-->V145_frequency_encoding: r^2=0.9905905586657651\n",
      "V144_frequency_encoding-->V166_frequency_encoding: r^2=0.9990991765503099\n",
      "V145_frequency_encoding-->V144_frequency_encoding: r^2=0.9905905586657651\n",
      "V146_frequency_encoding-->V147_frequency_encoding: r^2=1.0\n",
      "V147_frequency_encoding-->V146_frequency_encoding: r^2=1.0\n",
      "V148_frequency_encoding-->V149_frequency_encoding: r^2=1.0\n",
      "V148_frequency_encoding-->V153_frequency_encoding: r^2=1.0\n",
      "V148_frequency_encoding-->V154_frequency_encoding: r^2=1.0\n",
      "V149_frequency_encoding-->V148_frequency_encoding: r^2=1.0\n",
      "V155_frequency_encoding-->V156_frequency_encoding: r^2=1.0\n",
      "V156_frequency_encoding-->V155_frequency_encoding: r^2=1.0\n",
      "V157_frequency_encoding-->V158_frequency_encoding: r^2=0.9919818206642547\n",
      "V158_frequency_encoding-->V157_frequency_encoding: r^2=0.9919818206642547\n",
      "V164_frequency_encoding-->V143_frequency_encoding: r^2=0.9950360464392075\n",
      "V167_frequency_encoding-->V202_frequency_encoding: r^2=0.9980677390055043\n",
      "V170_frequency_encoding-->V171_frequency_encoding: r^2=0.9857396723461876\n",
      "V171_frequency_encoding-->V170_frequency_encoding: r^2=0.9857396723461876\n",
      "V172_frequency_encoding-->V205_frequency_encoding: r^2=0.9996656842637289\n",
      "V173_frequency_encoding-->V206_frequency_encoding: r^2=0.999716357840001\n",
      "V174_frequency_encoding-->V175_frequency_encoding: r^2=0.9999342984922764\n",
      "V174_frequency_encoding-->V208_frequency_encoding: r^2=0.999293973279445\n",
      "V174_frequency_encoding-->V210_frequency_encoding: r^2=0.999293973279445\n",
      "V175_frequency_encoding-->V174_frequency_encoding: r^2=0.9999342984922764\n",
      "V177_frequency_encoding-->V211_frequency_encoding: r^2=0.9998481166744403\n",
      "V178_frequency_encoding-->V212_frequency_encoding: r^2=0.9998226883488911\n",
      "V179_frequency_encoding-->V213_frequency_encoding: r^2=0.9998533206916764\n",
      "V180_frequency_encoding-->V182_frequency_encoding: r^2=0.9999997320078999\n",
      "V180_frequency_encoding-->V215_frequency_encoding: r^2=0.9994285062717123\n",
      "V181_frequency_encoding-->V214_frequency_encoding: r^2=0.9995701349502724\n",
      "V182_frequency_encoding-->V180_frequency_encoding: r^2=0.9999997320078999\n",
      "V183_frequency_encoding-->V216_frequency_encoding: r^2=0.9995226937364009\n",
      "V184_frequency_encoding-->V185_frequency_encoding: r^2=0.9999875226540341\n",
      "V185_frequency_encoding-->V184_frequency_encoding: r^2=0.9999875226540341\n",
      "V188_frequency_encoding-->V189_frequency_encoding: r^2=1.0\n",
      "V189_frequency_encoding-->V188_frequency_encoding: r^2=1.0\n",
      "V191_frequency_encoding-->V193_frequency_encoding: r^2=1.0\n",
      "V193_frequency_encoding-->V191_frequency_encoding: r^2=1.0\n",
      "V194_frequency_encoding-->V195_frequency_encoding: r^2=1.0\n",
      "V195_frequency_encoding-->V194_frequency_encoding: r^2=1.0\n",
      "V197_frequency_encoding-->V198_frequency_encoding: r^2=1.0\n",
      "V198_frequency_encoding-->V197_frequency_encoding: r^2=1.0\n",
      "V200_frequency_encoding-->V201_frequency_encoding: r^2=1.0\n",
      "V201_frequency_encoding-->V200_frequency_encoding: r^2=1.0\n",
      "V202_frequency_encoding-->V167_frequency_encoding: r^2=0.9980677390055043\n",
      "V205_frequency_encoding-->V172_frequency_encoding: r^2=0.9996656842637289\n",
      "V206_frequency_encoding-->V173_frequency_encoding: r^2=0.999716357840001\n",
      "V211_frequency_encoding-->V177_frequency_encoding: r^2=0.9998481166744403\n",
      "V212_frequency_encoding-->V178_frequency_encoding: r^2=0.9998226883488911\n",
      "V213_frequency_encoding-->V179_frequency_encoding: r^2=0.9998533206916764\n",
      "V214_frequency_encoding-->V181_frequency_encoding: r^2=0.9995701349502724\n",
      "V216_frequency_encoding-->V183_frequency_encoding: r^2=0.9995226937364009\n",
      "V217_frequency_encoding-->V263_frequency_encoding: r^2=0.9981160782044315\n",
      "V223_frequency_encoding-->V225_frequency_encoding: r^2=0.9872575461411573\n",
      "V223_frequency_encoding-->V266_frequency_encoding: r^2=0.9997199807739084\n",
      "V223_frequency_encoding-->V268_frequency_encoding: r^2=0.9861275837960614\n",
      "V224_frequency_encoding-->V267_frequency_encoding: r^2=0.9993430158456861\n",
      "V225_frequency_encoding-->V223_frequency_encoding: r^2=0.9872575461411573\n",
      "V227_frequency_encoding-->V271_frequency_encoding: r^2=0.9997697390593834\n",
      "V227_frequency_encoding-->V272_frequency_encoding: r^2=0.9997697390593834\n",
      "V231_frequency_encoding-->V273_frequency_encoding: r^2=0.9998809373464793\n",
      "V232_frequency_encoding-->V274_frequency_encoding: r^2=0.9998718809270489\n",
      "V233_frequency_encoding-->V275_frequency_encoding: r^2=0.9998906835954565\n",
      "V234_frequency_encoding-->V236_frequency_encoding: r^2=0.9999900239839871\n",
      "V234_frequency_encoding-->V277_frequency_encoding: r^2=0.9990558880970112\n",
      "V235_frequency_encoding-->V276_frequency_encoding: r^2=0.9994702863327767\n",
      "V236_frequency_encoding-->V234_frequency_encoding: r^2=0.9999900239839871\n",
      "V237_frequency_encoding-->V278_frequency_encoding: r^2=0.9992984027578604\n",
      "V238_frequency_encoding-->V239_frequency_encoding: r^2=0.9898988541796404\n",
      "V239_frequency_encoding-->V238_frequency_encoding: r^2=0.9898988541796404\n",
      "V242_frequency_encoding-->V244_frequency_encoding: r^2=1.0\n",
      "V244_frequency_encoding-->V242_frequency_encoding: r^2=1.0\n",
      "V247_frequency_encoding-->V249_frequency_encoding: r^2=0.9999962760952628\n",
      "V249_frequency_encoding-->V247_frequency_encoding: r^2=0.9999962760952628\n",
      "V250_frequency_encoding-->V251_frequency_encoding: r^2=1.0\n",
      "V251_frequency_encoding-->V250_frequency_encoding: r^2=1.0\n",
      "V263_frequency_encoding-->V217_frequency_encoding: r^2=0.9981160782044315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V267_frequency_encoding-->V224_frequency_encoding: r^2=0.9993430158456861\n",
      "V271_frequency_encoding-->V227_frequency_encoding: r^2=0.9997697390593834\n",
      "V273_frequency_encoding-->V231_frequency_encoding: r^2=0.9998809373464793\n",
      "V274_frequency_encoding-->V232_frequency_encoding: r^2=0.9998718809270489\n",
      "V275_frequency_encoding-->V233_frequency_encoding: r^2=0.9998906835954565\n",
      "V276_frequency_encoding-->V235_frequency_encoding: r^2=0.9994702863327767\n",
      "V278_frequency_encoding-->V237_frequency_encoding: r^2=0.9992984027578604\n",
      "V279_frequency_encoding-->V306_frequency_encoding: r^2=0.998748178980935\n",
      "V280_frequency_encoding-->V308_frequency_encoding: r^2=0.9984652163932172\n",
      "V284_frequency_encoding-->V309_frequency_encoding: r^2=0.9998797471119718\n",
      "V285_frequency_encoding-->V310_frequency_encoding: r^2=0.9995424808121213\n",
      "V286_frequency_encoding-->V311_frequency_encoding: r^2=0.9999477710893123\n",
      "V287_frequency_encoding-->V312_frequency_encoding: r^2=0.999757931559884\n",
      "V288_frequency_encoding-->V289_frequency_encoding: r^2=0.9998024822551095\n",
      "V288_frequency_encoding-->V313_frequency_encoding: r^2=0.9998968719157693\n",
      "V288_frequency_encoding-->V315_frequency_encoding: r^2=0.999894671629694\n",
      "V289_frequency_encoding-->V288_frequency_encoding: r^2=0.9998024822551095\n",
      "V293_frequency_encoding-->V316_frequency_encoding: r^2=0.9999447343655575\n",
      "V294_frequency_encoding-->V317_frequency_encoding: r^2=0.9998878491237994\n",
      "V295_frequency_encoding-->V318_frequency_encoding: r^2=0.9999017237445925\n",
      "V296_frequency_encoding-->V298_frequency_encoding: r^2=0.9999726919290476\n",
      "V296_frequency_encoding-->V320_frequency_encoding: r^2=0.9998016900962627\n",
      "V297_frequency_encoding-->V299_frequency_encoding: r^2=1.0\n",
      "V297_frequency_encoding-->V319_frequency_encoding: r^2=0.9997998118381628\n",
      "V297_frequency_encoding-->V321_frequency_encoding: r^2=0.9997998118381628\n",
      "V298_frequency_encoding-->V296_frequency_encoding: r^2=0.9999726919290476\n",
      "V299_frequency_encoding-->V297_frequency_encoding: r^2=1.0\n",
      "V300_frequency_encoding-->V301_frequency_encoding: r^2=1.0\n",
      "V301_frequency_encoding-->V300_frequency_encoding: r^2=1.0\n",
      "V306_frequency_encoding-->V279_frequency_encoding: r^2=0.998748178980935\n",
      "V308_frequency_encoding-->V280_frequency_encoding: r^2=0.9984652163932172\n",
      "V309_frequency_encoding-->V284_frequency_encoding: r^2=0.9998797471119718\n",
      "V310_frequency_encoding-->V285_frequency_encoding: r^2=0.9995424808121213\n",
      "V311_frequency_encoding-->V286_frequency_encoding: r^2=0.9999477710893123\n",
      "V312_frequency_encoding-->V287_frequency_encoding: r^2=0.999757931559884\n",
      "V316_frequency_encoding-->V293_frequency_encoding: r^2=0.9999447343655575\n",
      "V317_frequency_encoding-->V294_frequency_encoding: r^2=0.9998878491237994\n",
      "V318_frequency_encoding-->V295_frequency_encoding: r^2=0.9999017237445925\n",
      "V322_frequency_encoding-->V331_frequency_encoding: r^2=0.9983547433981788\n",
      "V323_frequency_encoding-->V332_frequency_encoding: r^2=0.9967653305597345\n",
      "V324_frequency_encoding-->V333_frequency_encoding: r^2=0.9980618408455646\n",
      "V325_frequency_encoding-->V334_frequency_encoding: r^2=0.9999621107411024\n",
      "V326_frequency_encoding-->V335_frequency_encoding: r^2=0.9992763663103\n",
      "V327_frequency_encoding-->V336_frequency_encoding: r^2=0.9996521206534761\n",
      "V328_frequency_encoding-->V337_frequency_encoding: r^2=0.9993364567376631\n",
      "V329_frequency_encoding-->V338_frequency_encoding: r^2=0.9990514020748981\n",
      "V330_frequency_encoding-->V339_frequency_encoding: r^2=0.9992111208538232\n",
      "V331_frequency_encoding-->V322_frequency_encoding: r^2=0.9983547433981788\n",
      "V332_frequency_encoding-->V323_frequency_encoding: r^2=0.9967653305597345\n",
      "V333_frequency_encoding-->V324_frequency_encoding: r^2=0.9980618408455646\n",
      "V334_frequency_encoding-->V325_frequency_encoding: r^2=0.9999621107411024\n",
      "V335_frequency_encoding-->V326_frequency_encoding: r^2=0.9992763663103\n",
      "V336_frequency_encoding-->V327_frequency_encoding: r^2=0.9996521206534761\n",
      "V337_frequency_encoding-->V328_frequency_encoding: r^2=0.9993364567376631\n",
      "V338_frequency_encoding-->V329_frequency_encoding: r^2=0.9990514020748981\n",
      "V339_frequency_encoding-->V330_frequency_encoding: r^2=0.9992111208538232\n",
      "id_07_frequency_encoding-->id_27: r^2=0.9999989566501299\n",
      "id_12_frequency_encoding-->id_12: r^2=0.9999999999999928\n",
      "id_15_frequency_encoding-->id_16_frequency_encoding: r^2=0.9812930253315056\n",
      "id_16_frequency_encoding-->id_15_frequency_encoding: r^2=0.9812930253315056\n",
      "id_34_frequency_encoding-->id_34: r^2=0.9852586415863963\n",
      "781 columns total\n",
      "305 columns left\n",
      "The set of remaining columns should be modified. Error: \"['isFraud'] not in index\"\n",
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>292</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>305</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train  test\n",
       "column type                     \n",
       "categorical_integer    292   291\n",
       "categorical_string       0     0\n",
       "continuous              13    13\n",
       "date                     0     0\n",
       "json                     0     0\n",
       "other                    0     0\n",
       "total amount           305   304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "\u001b[1m\u001b[35mApply target-based encoding to the categorical features by applying the following function:\n",
      "\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.features_encoding(\"target\", dataframe_dict: dict, reference: str, ignore_columns: list, target: str)\u001b[m\u001b[m\n",
      "\u001b[35mAn example of the ignore_columns list: \n",
      "\u001b[m\u001b[32m\u001b[40m ignore_columns = ['id', 'target']\n",
      "\u001b[m\n",
      "\u001b[35mAn example of the reference: \n",
      "\u001b[m\u001b[32m\u001b[40m reference = 'train'\n",
      "\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.drop_correlated_columns(dataframe_dict, ignore_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = [\"TransactionID\", \"isFraud\"]\n",
    "reference = \"train\"\n",
    "target = \"isFraud\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>292</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>305</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train  test\n",
       "column type                     \n",
       "categorical_integer    292   291\n",
       "categorical_string       0     0\n",
       "continuous              13    13\n",
       "date                     0     0\n",
       "json                     0     0\n",
       "other                    0     0\n",
       "total amount           305   304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "\u001b[1m\u001b[35mIf you have numeric features, it is a good idea to normalize numeric features.Use the following function for feature normalization:\n",
      "\u001b[m\u001b[32m\u001b[40m dataframe_dict, columns_set = flow.scale_data (dataframe_dict: dict, ignore_columns: list)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mignore_columns = ['id', 'target']\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.features_encoding(\"target\",\n",
    "                                                     dataframe_dict,\n",
    "                                                     reference=reference,\n",
    "                                                     ignore_columns=ignore_columns,\n",
    "                                                     target_name=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = [\"TransactionID\", \"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A summary of the data sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>categorical_integer</th>\n",
       "      <td>292</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_string</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continuous</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>json</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total amount</th>\n",
       "      <td>305</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     train  test\n",
       "column type                     \n",
       "categorical_integer    292   291\n",
       "categorical_string       0     0\n",
       "continuous              13    13\n",
       "date                     0     0\n",
       "json                     0     0\n",
       "other                    0     0\n",
       "total amount           305   304"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "\u001b[1m\u001b[35mIf you want to explore the data you can run one of the following functions: \u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35m1 . \u001b[m\u001b[32m\u001b[40mflow.exploring_data(dataframe_dict: dict, key_i: str)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mflow.exploring_data(dataframe_dict, 'train')\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35m2 . \u001b[m\u001b[32m\u001b[40mflow.comparing_statistics(dataframe_dict: dict)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mflow.comparing_statistics(dataframe_dict)\u001b[m\u001b[m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[35mYour features are ready to train the model: \u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mYou can start training the model by applying the following function: \u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mmodel_index_list, save_models_dir, y_test = flow.training(parameters)\u001b[m\n",
      "parameters = {\n",
      "     \"data\": {\n",
      "         \"train\": {\"features\": train_dataframe, \"target\": train_target}, \n",
      "         \"valid\": {\"features\": valid_dataframe, \"target\": valid_target}, \n",
      "         \"test\": {\"features\": test_dataframe, \"target\": test_target}, \n",
      "     }, \n",
      "     \"split\": {\n",
      "         \"method\": \"split\",\n",
      "         \"split_ratios\": 0.2\n",
      "         }, \n",
      "      \"model\": {\"type\": \"Ridge linear regression\",\n",
      "               \"hyperparameters\": {\"alpha\": 1,  # alpha:optimize}\n",
      "             }, \n",
      "      \"metrics\": [\"r2_score\", \"mean_squared_error\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.scale_data(dataframe_dict, ignore_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ae68dd63bb40edb8086e99b039f5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='column_i', max=303), Output()), _dom_classes=('widget-in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow.exploring_data(dataframe_dict, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c1b633656c4bbc883f9e2bf7a01df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature_nr', max=304), Output()), _dom_classes=('widget-…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow.comparing_statistics(dataframe_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check if the directory ./data/flow_3/post_processing exists\n",
      " will be added to the end of the filename\n",
      "saving train dataset to ./data/flow_3/post_processing/train_.csv file\n",
      "saving test dataset to ./data/flow_3/post_processing/test_.csv file\n",
      "It seems that the next step is not defined. Error'9'\n",
      "\u001b[1m\u001b[35mPlease use the following function to read the data\u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.load_data(path : str, files_list : list)\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mpath = ./data/flow_3/post_processing\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mIf your data is in a nested directory, it is better to os.path.join. For example:\n",
      "\u001b[m\u001b[32m\u001b[40mpath = os.path.join('data', 'flow_0')\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mfiles_list = [train_.csv, test_.csv]\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mThe output is a dictionary that contains dataframes e.g.\n",
      "\u001b[m\u001b[m\n",
      "\u001b[34mdataframe_dict = {'train': train_dataframe,'test': test_dataframe}\u001b[m\n"
     ]
    }
   ],
   "source": [
    "flow.save_post_processed_data(dataframe_dict, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dataframe_dict[\"train\"].columns\n",
    "total_columns = columns_set[\"train\"][\"continuous\"] +\\\n",
    "columns_set[\"train\"][\"categorical_integer\"]\n",
    "\n",
    "train_dataframe = dataframe_dict[\"train\"][\n",
    "    [x for x in total_columns if x not in ignore_columns]]\n",
    "test_dataframe = dataframe_dict[\"test\"][\n",
    "    [x for x in total_columns if x not in ignore_columns]]\n",
    "train_target = dataframe_dict[\"train\"][\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"data\": {\n",
    "        \"train\": {\"features\": train_dataframe, \"target\": train_target.to_numpy()},\n",
    "    },\n",
    "    \"split\": {\n",
    "        \"method\": \"kfold\",  # \"method\":\"kfold\"\n",
    "        \"fold_nr\": 5,  # foldnr:5 , \"split_ratios\": 0.8 # \"split_ratios\":(0.7,0.2)\n",
    "    },\n",
    "    \"model\": {\"type\": \"Logistic regression\",\n",
    "              \"hyperparameters\": {},\n",
    "              },\n",
    "    \"metrics\": [\"accuracy_score\", \"roc_auc_score\"],\n",
    "    \"predict\": {\n",
    "        \"test\": {\"features\": test_dataframe}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle is not provided: 'shuffle'\n",
      "random_state is not provided: 'random_state'\n",
      "fold_nr. 1\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.9429, 'roc_auc_score (train.validation)': 0.7348484848484849}\n",
      "fold_nr. 2\n",
      "Error during metric calculation: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "metric value set to np.nan \n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.9714, 'roc_auc_score (train.validation)': nan}\n",
      "fold_nr. 3\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.9571, 'roc_auc_score (train.validation)': 0.7424242424242424}\n",
      "fold_nr. 4\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.942, 'roc_auc_score (train.validation)': 0.6515151515151515}\n",
      "fold_nr. 5\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.8986, 'roc_auc_score (train.validation)': 0.6287878787878788}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_1</th>\n",
       "      <th>fold_2</th>\n",
       "      <th>fold_3</th>\n",
       "      <th>fold_4</th>\n",
       "      <th>fold_5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train.train)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train.validation)</th>\n",
       "      <td>0.942900</td>\n",
       "      <td>0.9714</td>\n",
       "      <td>0.957100</td>\n",
       "      <td>0.942000</td>\n",
       "      <td>0.898600</td>\n",
       "      <td>0.942400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train.train)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train.validation)</th>\n",
       "      <td>0.734848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.628788</td>\n",
       "      <td>0.689394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     fold_1  fold_2    fold_3    fold_4  \\\n",
       "accuracy_score (train.train)       1.000000  1.0000  1.000000  1.000000   \n",
       "accuracy_score (train.validation)  0.942900  0.9714  0.957100  0.942000   \n",
       "roc_auc_score (train.train)        1.000000  1.0000  1.000000  1.000000   \n",
       "roc_auc_score (train.validation)   0.734848     NaN  0.742424  0.651515   \n",
       "\n",
       "                                     fold_5      mean  \n",
       "accuracy_score (train.train)       1.000000  1.000000  \n",
       "accuracy_score (train.validation)  0.898600  0.942400  \n",
       "roc_auc_score (train.train)        1.000000  1.000000  \n",
       "roc_auc_score (train.validation)   0.628788  0.689394  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model 1</th>\n",
       "      <th>model 2</th>\n",
       "      <th>model 3</th>\n",
       "      <th>model 4</th>\n",
       "      <th>model 5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train)</th>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.994300</td>\n",
       "      <td>0.991400</td>\n",
       "      <td>0.988500</td>\n",
       "      <td>0.979900</td>\n",
       "      <td>0.988520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train)</th>\n",
       "      <td>0.925577</td>\n",
       "      <td>0.997006</td>\n",
       "      <td>0.927074</td>\n",
       "      <td>0.925577</td>\n",
       "      <td>0.921086</td>\n",
       "      <td>0.939264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model 1   model 2   model 3   model 4   model 5  \\\n",
       "accuracy_score (train)  0.988500  0.994300  0.991400  0.988500  0.979900   \n",
       "roc_auc_score (train)   0.925577  0.997006  0.927074  0.925577  0.921086   \n",
       "\n",
       "                            mean  \n",
       "accuracy_score (train)  0.988520  \n",
       "roc_auc_score (train)   0.939264  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the end of the flow\n"
     ]
    }
   ],
   "source": [
    "model_index_list_logistic, save_models_dir_logistic, y_test_logistic = flow.training(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lighgbm = {\n",
    "    \"data\": {\n",
    "        \"train\": {\"features\": train_dataframe, \"target\": train_target.to_numpy()},\n",
    "    },\n",
    "    \"split\": {\n",
    "        \"method\": \"kfold\",  # \"method\":\"kfold\"\n",
    "        \"fold_nr\": 5,  # foldnr:5 , \"split_ratios\": 0.8 # \"split_ratios\":(0.7,0.2)\n",
    "    },\n",
    "    \"model\": {\"type\": \"lightgbm\",\n",
    "              \"hyperparameters\": dict(objective='binary', metric='cross-entropy', num_leaves=5,\n",
    "                                      boost_from_average=True,\n",
    "                                      learning_rate=0.05, bagging_fraction=0.99, feature_fraction=0.99, max_depth=-1,\n",
    "                                      num_rounds=10000, min_data_in_leaf=10, boosting='dart')\n",
    "              },\n",
    "    \"metrics\": [\"accuracy_score\", \"roc_auc_score\"],\n",
    "    \"predict\": {\n",
    "        \"test\": {\"features\": test_dataframe}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle is not provided: 'shuffle'\n",
      "random_state is not provided: 'random_state'\n",
      "fold_nr. 1\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.9714, 'roc_auc_score (train.validation)': 0.7689393939393939}\n",
      "fold_nr. 2\n",
      "Error during metric calculation: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
      "metric value set to np.nan \n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 1.0, 'roc_auc_score (train.validation)': nan}\n",
      "fold_nr. 3\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.9714, 'roc_auc_score (train.validation)': 0.9583333333333334}\n",
      "fold_nr. 4\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.971, 'roc_auc_score (train.validation)': 0.9848484848484849}\n",
      "fold_nr. 5\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.9855, 'roc_auc_score (train.validation)': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_1</th>\n",
       "      <th>fold_2</th>\n",
       "      <th>fold_3</th>\n",
       "      <th>fold_4</th>\n",
       "      <th>fold_5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train.train)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train.validation)</th>\n",
       "      <td>0.971400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971400</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.9855</td>\n",
       "      <td>0.97986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train.train)</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train.validation)</th>\n",
       "      <td>0.768939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.92803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     fold_1  fold_2    fold_3    fold_4  \\\n",
       "accuracy_score (train.train)       1.000000     1.0  1.000000  1.000000   \n",
       "accuracy_score (train.validation)  0.971400     1.0  0.971400  0.971000   \n",
       "roc_auc_score (train.train)        1.000000     1.0  1.000000  1.000000   \n",
       "roc_auc_score (train.validation)   0.768939     NaN  0.958333  0.984848   \n",
       "\n",
       "                                   fold_5     mean  \n",
       "accuracy_score (train.train)       1.0000  1.00000  \n",
       "accuracy_score (train.validation)  0.9855  0.97986  \n",
       "roc_auc_score (train.train)        1.0000  1.00000  \n",
       "roc_auc_score (train.validation)   1.0000  0.92803  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model 1</th>\n",
       "      <th>model 2</th>\n",
       "      <th>model 3</th>\n",
       "      <th>model 4</th>\n",
       "      <th>model 5</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train)</th>\n",
       "      <td>0.994300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99430</td>\n",
       "      <td>0.994300</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>0.996000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train)</th>\n",
       "      <td>0.943969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99166</td>\n",
       "      <td>0.999358</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.986997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model 1  model 2  model 3   model 4  model 5  \\\n",
       "accuracy_score (train)  0.994300      1.0  0.99430  0.994300   0.9971   \n",
       "roc_auc_score (train)   0.943969      1.0  0.99166  0.999358   1.0000   \n",
       "\n",
       "                            mean  \n",
       "accuracy_score (train)  0.996000  \n",
       "roc_auc_score (train)   0.986997  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the end of the flow\n"
     ]
    }
   ],
   "source": [
    "model_index_list_lightgbm, save_models_dir_lightgbm, y_test_lightgbm = flow.training(parameters_lighgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_xgboost = {\n",
    "    \"data\": {\n",
    "        \"train\": {\"features\": train_dataframe, \"target\": train_target.to_numpy()},\n",
    "    },\n",
    "    \"split\": {\n",
    "        \"method\": \"kfold\",  # \"method\":\"kfold\"\n",
    "        \"fold_nr\": 5,  # fold_nr:5 , \"split_ratios\": 0.3 # \"split_ratios\":(0.3,0.2)\n",
    "    },\n",
    "    \"model\": {\"type\": \"xgboost\",\n",
    "              \"hyperparameters\": {'max_depth': 5, 'eta': 1, 'eval_metric': \"auc\", 'objective':'binary:logistic'}\n",
    "              },\n",
    "    \"metrics\": [\"accuracy_score\", \"roc_auc_score\"],\n",
    "    \"predict\": {\n",
    "        \"test\": {\"features\": test_dataframe}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle is not provided: 'shuffle'\n",
      "random_state is not provided: 'random_state'\n",
      "fold_nr. 1\n",
      "The num_round is not defined. The default value is num_round = 10. Error: 'num_round'\n",
      "[0]\ttrain-auc:0.930037\ttest-auc:0.708333\n",
      "[1]\ttrain-auc:0.999254\ttest-auc:0.662879\n",
      "[2]\ttrain-auc:1\ttest-auc:0.715909\n",
      "[3]\ttrain-auc:1\ttest-auc:0.683712\n",
      "[4]\ttrain-auc:1\ttest-auc:0.674242\n",
      "[5]\ttrain-auc:1\ttest-auc:0.729167\n",
      "[6]\ttrain-auc:1\ttest-auc:0.74053\n",
      "[7]\ttrain-auc:1\ttest-auc:0.755682\n",
      "[8]\ttrain-auc:1\ttest-auc:0.801136\n",
      "[9]\ttrain-auc:1\ttest-auc:0.782197\n",
      "{'accuracy_score (train.train)': 1.0, 'roc_auc_score (train.train)': 1.0, 'accuracy_score (train.validation)': 0.9571, 'roc_auc_score (train.validation)': 0.7821969696969697}\n",
      "fold_nr. 2\n",
      "The num_round is not defined. The default value is num_round = 10. Error: 'num_round'\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[12:20:15] src/metric/rank_metric.cc:200: Check failed: !auc_error: AUC: the dataset only contains pos or neg samples\nStack trace:\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-4ce998bec72d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_index_list_xgboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_models_dir_xgboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_xgboost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters_xgboost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/ML-Navigator/flows/flows.py\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, parameters)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mfunction_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mmodel_index_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_models_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"predict\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/training/training.py\u001b[0m in \u001b[0;36mmodel_training\u001b[0;34m(parameters)\u001b[0m\n\u001b[1;32m    416\u001b[0m                                                                        \u001b[0mmodels_nr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                                                                        \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m                                                                        parameters[\"metrics\"])\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# Evaluate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/training/training.py\u001b[0m in \u001b[0;36mtrain_with_kfold_cross_validation\u001b[0;34m(split, stratify, hyperparameters, train_array, target, models_nr, model_type, required_metrics)\u001b[0m\n\u001b[1;32m    255\u001b[0m                                                                   \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                                                                   \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                                                                   num_round)\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/training/xgboost_train.py\u001b[0m in \u001b[0;36mtraining_xgboost_kfold\u001b[0;34m(train_array, target, train, test, hyperparameters, num_round)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mvalidation_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost_data_preparation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgboost_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mkfold_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost_regression_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mkfold_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/training/xgboost_train.py\u001b[0m in \u001b[0;36mxgboost_regression_train\u001b[0;34m(validation_list, hyperparameters, num_round)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mparam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_round\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/venv/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/venv/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# check evaluation result.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0mbst_eval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst_eval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTRING_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbst_eval_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/venv/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36meval_set\u001b[0;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[1;32m   1170\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m                                               \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m                                               ctypes.byref(msg)))\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/ML-Navigator/venv/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \"\"\"\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [12:20:15] src/metric/rank_metric.cc:200: Check failed: !auc_error: AUC: the dataset only contains pos or neg samples\nStack trace:\n\n"
     ]
    }
   ],
   "source": [
    "model_index_list_xgboost, save_models_dir_xgboost, y_test_xgboost = flow.training(parameters_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataframe = dataframe_dict['train'].drop(['isFraud'],1)\n",
    "train_target = dataframe_dict[\"train\"][\"isFraud\"]\n",
    "\n",
    "test_dataframe = dataframe_dict['test']  #.drop(['isFraud'],1)\n",
    "\n",
    "parameters_sklearn = {\n",
    "    \"data\": {\n",
    "        \"train\": {\n",
    "            \"features\": train_dataframe,\n",
    "            \"target\": train_target.to_numpy()\n",
    "        }, \n",
    "    },\n",
    "    \"split\": {\n",
    "        \"method\": \"split\",\n",
    "        \"split_ratios\": 0.2,\n",
    "        \"stratify\": True\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"type\": \"sklearn.ensemble.RandomForestClassifier\",\n",
    "        \"hyperparameters\": {\n",
    "            'params_grid':{\n",
    "                'class_weight': [\"balanced_subsample\"],\n",
    "                'max_depth': [5, 10, 20, 999],\n",
    "                'min_samples_leaf': [10, 3, 1]\n",
    "            },\n",
    "            'params_fixed': {\n",
    "                'max_depth': 4, \n",
    "                'min_samples_split': 10, \n",
    "                'min_samples_leaf': 2, \n",
    "                'random_state': 11\n",
    "            },\n",
    "            'params_cv': {\n",
    "                'n_splits': 5, \n",
    "                'shuffle': True, \n",
    "                'random_state': 11\n",
    "            },\n",
    "            \"objective\": \"classification\",\n",
    "            \"grid_search_scoring\": ['roc_auc', 'accuracy']\n",
    "        },\n",
    "    },\n",
    "    \"metrics\": ['roc_auc_score', 'accuracy_score'],\n",
    "    \"predict\": {\n",
    "        \"test\": {\n",
    "            \"features\": test_dataframe\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train.train)</th>\n",
       "      <td>0.996400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train.validation_0)</th>\n",
       "      <td>0.985700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train.train)</th>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train.validation_0)</th>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      model 0\n",
       "accuracy_score (train.train)         0.996400\n",
       "accuracy_score (train.validation_0)  0.985700\n",
       "roc_auc_score (train.train)          0.954545\n",
       "roc_auc_score (train.validation_0)   0.833333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy_score (train)</th>\n",
       "      <td>0.994300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc_score (train)</th>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model 0\n",
       "accuracy_score (train)  0.994300\n",
       "roc_auc_score (train)   0.928571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the end of the flow\n"
     ]
    }
   ],
   "source": [
    "model_index_list_RF, save_models_dir_RF, y_test_RF = flow.training(parameters_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
