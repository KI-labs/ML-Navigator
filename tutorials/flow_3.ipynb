{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/m.dee/Documents/Data-science-package-beta/data-science-package\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"flow_3.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35mWelcome to the Data Science Package. First create an object as follows:\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example, use the code below to import the flow 0:\u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mflow = Flows(0)\u001b[m\n"
     ]
    }
   ],
   "source": [
    "from flows.flows import Flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[35mPlease use the following function to read the data\u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mdataframe_dict = flow.load_data(path: str, files_list: list)\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mpath = './data'\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mfiles_list = ['train.csv','test.csv']\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mThe output is a dictionary that contains dataframes e.g.  \u001b[m\u001b[m\n",
      "\u001b[34mdataframe_dict = {'train': train_dataframe,'test': test_dataframe}\u001b[m\n"
     ]
    }
   ],
   "source": [
    "flow = Flows(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/flow_3\"\n",
    "files_list = ['train_transaction.csv','test_transaction.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe summary of the train_transaction dataset:\u001b[0;0m\n",
      "The train_transaction dataset contains 394 columns\n",
      "There are 14 string categorical columns\n",
      "There are 326 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 54 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the train_transaction dataset **********\n",
      "\u001b[1mThe summary of the test_transaction dataset:\u001b[0;0m\n",
      "The test_transaction dataset contains 393 columns\n",
      "There are 14 string categorical columns\n",
      "There are 325 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 54 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the test_transaction dataset **********\n",
      "The possible ids are {'TransactionID'}\n",
      "The possible possible_target are ['isFraud']\n",
      "The type of the problem that should be solved {'isFraud': 'classification'}\n",
      "\u001b[1m\u001b[35mIf you have categorical features with string labels, Encode the categorical features by applying the following function:\n",
      "\u001b[m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.encode_categorical_feature(dataframe_dict: dict)\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.load_data(path, files_list, rows_amount=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['categorical_string', 'categorical_integer', 'continuous', 'date', 'json', 'other'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " columns_set[\"train_transaction\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reference dataframe is: train_transaction\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in ProductCD feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in card4 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in card6 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in P_emaildomain feature is: 47\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in R_emaildomain feature is: 32\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M1 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M2 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M3 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M4 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M5 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M6 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M7 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M8 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in M9 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in card3 feature is: 19\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in card5 feature is: 32\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in addr2 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in dist2 feature is: 74\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in C3 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in C4 feature is: 17\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in C7 feature is: 14\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in C8 feature is: 20\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in C10 feature is: 27\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in C12 feature is: 13\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in D6 feature is: 75\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in D7 feature is: 50\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in D9 feature is: 20\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in D12 feature is: 57\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in D13 feature is: 33\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in D14 feature is: 44\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V1 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V2 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V3 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V4 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V5 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V6 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V7 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V8 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V9 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V10 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V11 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V12 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V13 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V14 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V15 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V16 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V17 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V18 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V19 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V20 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V21 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V22 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V23 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V24 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V25 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V26 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V27 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V28 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V29 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V30 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V31 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V32 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V33 feature is: 3\n",
      "the are 2 datasets provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V34 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V35 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V36 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V37 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V38 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V39 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V40 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V41 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V42 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V43 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V44 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V45 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V46 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V47 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V48 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V49 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V50 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V51 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V52 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V53 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V54 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V55 feature is: 8\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V56 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V57 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V58 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V59 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V60 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V61 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V62 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V63 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V64 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V65 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V66 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V67 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V68 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V69 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V70 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V71 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V72 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V73 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V74 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V75 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V76 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V77 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V78 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V79 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V80 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V81 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V82 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V83 feature is: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V84 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V85 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V86 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V87 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V88 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V89 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V90 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V91 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V92 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V93 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V94 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V95 feature is: 16\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V96 feature is: 50\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V97 feature is: 27\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V98 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V99 feature is: 26\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V100 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V101 feature is: 16\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V102 feature is: 29\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V103 feature is: 28\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V104 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V105 feature is: 14\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V106 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V107 feature is: 1\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V108 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V109 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V110 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V111 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V112 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V113 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V114 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V115 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V116 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V117 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V118 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V119 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V120 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V121 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V122 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V123 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V124 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V125 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V129 feature is: 73\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V135 feature is: 108\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V137 feature is: 131\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V138 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V139 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V140 feature is: 16\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V141 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V142 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V143 feature is: 16\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V144 feature is: 16\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V145 feature is: 22\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V146 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V147 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V148 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V149 feature is: 8\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V150 feature is: 47\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V151 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V152 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V153 feature is: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V154 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V155 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V156 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V157 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V158 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V161 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V162 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V163 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V164 feature is: 26\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V165 feature is: 28\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V166 feature is: 40\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V167 feature is: 14\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V168 feature is: 19\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V169 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V170 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V171 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V172 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V173 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V174 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V175 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V176 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V177 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V178 feature is: 13\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V179 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V180 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V181 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V182 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V183 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V184 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V185 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V186 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V187 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V188 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V189 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V190 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V191 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V192 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V193 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V194 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V195 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V196 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V197 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V198 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V199 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V200 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V201 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V202 feature is: 79\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V205 feature is: 26\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V206 feature is: 18\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V207 feature is: 41\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V208 feature is: 30\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V209 feature is: 38\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V210 feature is: 31\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V211 feature is: 35\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V212 feature is: 43\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V213 feature is: 39\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V214 feature is: 33\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V215 feature is: 40\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V216 feature is: 34\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V217 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V218 feature is: 22\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V219 feature is: 15\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V220 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V221 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V222 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V223 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V224 feature is: 19\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V225 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V226 feature is: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V227 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V228 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V229 feature is: 14\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V230 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V231 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V232 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V233 feature is: 8\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V234 feature is: 16\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V235 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V236 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V237 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V238 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V239 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V240 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V241 feature is: 2\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V242 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V243 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V244 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V245 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V246 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V247 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V248 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V249 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V250 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V251 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V252 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V253 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V254 feature is: 8\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V255 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V256 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V257 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V258 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V259 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V260 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V261 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V262 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V263 feature is: 83\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V266 feature is: 28\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V267 feature is: 53\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V268 feature is: 37\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V269 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V270 feature is: 25\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V271 feature is: 27\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V272 feature is: 26\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V273 feature is: 33\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V274 feature is: 48\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V275 feature is: 40\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V276 feature is: 36\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V277 feature is: 48\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V278 feature is: 39\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V279 feature is: 18\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V280 feature is: 28\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V281 feature is: 8\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V282 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V283 feature is: 14\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V284 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V285 feature is: 27\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V286 feature is: 3\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V287 feature is: 11\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V288 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V289 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V290 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V291 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V292 feature is: 8\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V293 feature is: 18\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V294 feature is: 36\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V295 feature is: 31\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V296 feature is: 22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V297 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V298 feature is: 18\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V299 feature is: 12\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V300 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V301 feature is: 7\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V302 feature is: 5\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V303 feature is: 8\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V304 feature is: 6\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V305 feature is: 1\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V311 feature is: 64\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V322 feature is: 13\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V323 feature is: 25\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V324 feature is: 17\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V325 feature is: 4\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V326 feature is: 20\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V327 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V328 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V329 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V330 feature is: 9\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V331 feature is: 35\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V332 feature is: 58\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V333 feature is: 46\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V334 feature is: 10\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V335 feature is: 33\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V336 feature is: 20\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V337 feature is: 20\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V338 feature is: 25\n",
      "the are 2 datasets provided\n",
      "encoding the feature in the dataset train_transaction\n",
      "encoding the feature in the dataset test_transaction\n",
      "the number of classes in V339 feature is: 21\n",
      "\u001b[31m******************************\u001b[m\n",
      "\u001b[1mThe summary of the train_transaction dataset:\u001b[0;0m\n",
      "The train_transaction dataset contains 394 columns\n",
      "There are 0 string categorical columns\n",
      "There are 340 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 54 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the train_transaction dataset **********\n",
      "\u001b[1mThe summary of the test_transaction dataset:\u001b[0;0m\n",
      "The test_transaction dataset contains 393 columns\n",
      "There are 0 string categorical columns\n",
      "There are 339 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 54 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the test_transaction dataset **********\n",
      "\u001b[1m\u001b[35mIf some features have in all rows the same value, they have no influence on the target prediction. It is a good idea to delete such features:\n",
      "\u001b[m\u001b[32m\u001b[40mcoming soon!\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.encode_categorical_feature(dataframe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = ['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V107 1\n",
      "V111 1\n",
      "V113 1\n",
      "V117 1\n",
      "V305 1\n",
      "Constant columns count: 5\n",
      "394 columns total\n",
      "389 columns left\n",
      "The set of remaining columns should be modified. Error: \"['isFraud'] not in index\"\n",
      "\u001b[1mThe summary of the train_transaction dataset:\u001b[0;0m\n",
      "The train_transaction dataset contains 389 columns\n",
      "There are 0 string categorical columns\n",
      "There are 335 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 54 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the train_transaction dataset **********\n",
      "\u001b[1mThe summary of the test_transaction dataset:\u001b[0;0m\n",
      "The test_transaction dataset contains 388 columns\n",
      "There are 0 string categorical columns\n",
      "There are 334 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 54 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the test_transaction dataset **********\n",
      "\u001b[1m\u001b[35mIf some features are highly correlated, they do not provide more information about the target prediction. It is a good idea to drop such features but keep one:\n",
      "\u001b[m\u001b[32m\u001b[40mcoming soon!\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.drop_columns_constant_values(dataframe_dict, ignore_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with correlations more than 0.98 :\n",
      "C1-->C2: r^2=0.9835407950188769\n",
      "C1-->C6: r^2=0.9812737003964525\n",
      "C1-->C11: r^2=0.9909747200825073\n",
      "C1-->C14: r^2=0.9887578813098824\n",
      "C2-->C1: r^2=0.9835407950188769\n",
      "C14-->C9: r^2=0.9863081932843857\n",
      "D6-->D12: r^2=0.9818650779193284\n",
      "D12-->D6: r^2=0.9818650779193284\n",
      "M1-->V1: r^2=1.0\n",
      "M1-->V2: r^2=0.9965985324667695\n",
      "M1-->V3: r^2=0.9952436281820471\n",
      "M1-->V4: r^2=0.9850001933811968\n",
      "M1-->V5: r^2=0.9899654270654655\n",
      "M1-->V6: r^2=0.9981294698320732\n",
      "M1-->V7: r^2=0.997135812936052\n",
      "M1-->V8: r^2=0.9981294698320732\n",
      "M1-->V9: r^2=0.9973606874850252\n",
      "M1-->V11: r^2=0.9879778663680381\n",
      "V1-->M1: r^2=1.0\n",
      "V11-->V10: r^2=0.992451033861086\n",
      "V12-->V13: r^2=0.9929947990022691\n",
      "V13-->V12: r^2=0.9929947990022691\n",
      "V14-->V17: r^2=0.9841955597731995\n",
      "V14-->V18: r^2=0.9841955597731995\n",
      "V14-->V23: r^2=0.9900571549039844\n",
      "V14-->V24: r^2=0.9852809338973325\n",
      "V14-->V25: r^2=0.9922661532645525\n",
      "V14-->V26: r^2=0.9854542185667928\n",
      "V14-->V27: r^2=0.9968802900331691\n",
      "V14-->V28: r^2=0.9968802900331691\n",
      "V15-->V16: r^2=1.0\n",
      "V15-->V21: r^2=0.9842881630189386\n",
      "V15-->V22: r^2=0.9843827349815998\n",
      "V15-->V31: r^2=0.9979538043385323\n",
      "V15-->V32: r^2=0.9979538043385323\n",
      "V15-->V33: r^2=0.9884373599662872\n",
      "V15-->V34: r^2=1.0\n",
      "V16-->V15: r^2=1.0\n",
      "V17-->V14: r^2=0.9841955597731995\n",
      "V19-->V20: r^2=0.987165777694072\n",
      "V20-->V19: r^2=0.987165777694072\n",
      "V29-->V30: r^2=0.9886263351329359\n",
      "V30-->V29: r^2=0.9886263351329359\n",
      "V35-->V36: r^2=0.9962054031378883\n",
      "V36-->V35: r^2=0.9962054031378883\n",
      "V37-->V38: r^2=0.9967658471402888\n",
      "V37-->V39: r^2=0.9890193942185553\n",
      "V37-->V40: r^2=0.9884551426666709\n",
      "V37-->V41: r^2=0.9950746880313098\n",
      "V37-->V43: r^2=0.9825814637160329\n",
      "V37-->V44: r^2=0.9947117945419467\n",
      "V37-->V45: r^2=0.9934966088926056\n",
      "V37-->V46: r^2=0.9900293982290302\n",
      "V37-->V47: r^2=0.9950397973866859\n",
      "V38-->V37: r^2=0.9967658471402888\n",
      "V39-->V42: r^2=0.9950781590648021\n",
      "V39-->V51: r^2=0.9882574561326203\n",
      "V39-->V52: r^2=0.9882574561326203\n",
      "V42-->V50: r^2=0.982632835516426\n",
      "V48-->V49: r^2=0.9988488234177132\n",
      "V49-->V48: r^2=0.9988488234177132\n",
      "V53-->V54: r^2=0.9850599269225412\n",
      "V54-->V53: r^2=0.9850599269225412\n",
      "V55-->V56: r^2=0.9911627093487926\n",
      "V55-->V65: r^2=0.9848198098290035\n",
      "V55-->V66: r^2=0.9853653471111329\n",
      "V55-->V68: r^2=0.9867850315378626\n",
      "V56-->V55: r^2=0.9911627093487926\n",
      "V57-->V58: r^2=1.0\n",
      "V57-->V63: r^2=0.9835677180555246\n",
      "V57-->V64: r^2=0.9815087715179162\n",
      "V57-->V71: r^2=0.9976541074271901\n",
      "V57-->V72: r^2=0.9976541074271901\n",
      "V57-->V73: r^2=0.9963132925669417\n",
      "V57-->V74: r^2=0.9963132925669417\n",
      "V58-->V57: r^2=1.0\n",
      "V59-->V60: r^2=0.9993731137144641\n",
      "V60-->V59: r^2=0.9993731137144641\n",
      "V61-->V62: r^2=0.9926721662378878\n",
      "V62-->V61: r^2=0.9926721662378878\n",
      "V65-->V67: r^2=0.9841072937206259\n",
      "V69-->V70: r^2=0.9889138434988866\n",
      "V70-->V69: r^2=0.9889138434988866\n",
      "V75-->V76: r^2=0.9881365126803267\n",
      "V76-->V75: r^2=0.9881365126803267\n",
      "V77-->V78: r^2=0.9970836385402057\n",
      "V77-->V80: r^2=0.9821370890603282\n",
      "V77-->V81: r^2=0.980093218988314\n",
      "V77-->V86: r^2=0.9873411113151639\n",
      "V77-->V88: r^2=0.9853577488523635\n",
      "V77-->V89: r^2=0.9901499755097746\n",
      "V78-->V77: r^2=0.9970836385402057\n",
      "V79-->V84: r^2=0.9810105810364441\n",
      "V79-->V85: r^2=0.9839634272159901\n",
      "V79-->V92: r^2=0.9979980502216272\n",
      "V79-->V93: r^2=0.9973971215654418\n",
      "V80-->V79: r^2=0.9877993058022803\n",
      "V82-->V83: r^2=0.9834558408794161\n",
      "V83-->V82: r^2=0.9834558408794161\n",
      "V86-->V87: r^2=0.9929283720946529\n",
      "V90-->V91: r^2=0.9878374778599748\n",
      "V91-->V90: r^2=0.9878374778599748\n",
      "V118-->V119: r^2=1.0\n",
      "V119-->V118: r^2=1.0\n",
      "V121-->V122: r^2=1.0\n",
      "V122-->V121: r^2=1.0\n",
      "V138-->V139: r^2=0.9829631015431477\n",
      "V138-->V140: r^2=0.9865157964261319\n",
      "V138-->V141: r^2=0.9988529347855813\n",
      "V138-->V142: r^2=0.9963892279878054\n",
      "V138-->V146: r^2=0.9919220828053783\n",
      "V138-->V147: r^2=0.9957654467391582\n",
      "V138-->V149: r^2=0.995735493853475\n",
      "V138-->V154: r^2=0.9883594135782531\n",
      "V138-->V156: r^2=0.9962541245071039\n",
      "V138-->V158: r^2=0.995801101656661\n",
      "V138-->V161: r^2=0.9988058227310446\n",
      "V138-->V162: r^2=0.9977599160309941\n",
      "V138-->V163: r^2=0.998201257326469\n",
      "V138-->V322: r^2=0.9889243685900915\n",
      "V138-->V323: r^2=0.981799796602177\n",
      "V138-->V324: r^2=0.9898545423224296\n",
      "V138-->V325: r^2=0.9981921697774387\n",
      "V138-->V326: r^2=0.9871323220539916\n",
      "V138-->V327: r^2=0.9976184771020545\n",
      "V138-->V328: r^2=0.9889258713815507\n",
      "V138-->V329: r^2=0.9874244781708957\n",
      "V138-->V330: r^2=0.9888902272937474\n",
      "V138-->V334: r^2=0.9959262458587936\n",
      "V138-->V335: r^2=0.9855899016708437\n",
      "V138-->V336: r^2=0.9900405542312647\n",
      "V138-->V337: r^2=0.9803502652931139\n",
      "V139-->V138: r^2=0.9829631015431477\n",
      "V139-->V148: r^2=0.9928516790796218\n",
      "V139-->V153: r^2=0.9928516790796218\n",
      "V139-->V155: r^2=0.9929294701515035\n",
      "V139-->V157: r^2=0.9938141026800529\n",
      "V144-->V145: r^2=0.993889697003115\n",
      "V145-->V144: r^2=0.993889697003115\n",
      "V146-->V338: r^2=0.9808769616389547\n",
      "V146-->V339: r^2=0.9863158252430206\n",
      "V151-->V164: r^2=0.9860663006312356\n",
      "V151-->V165: r^2=0.9860465424466072\n",
      "V152-->V159: r^2=0.9956763214995289\n",
      "V152-->V160: r^2=0.9962033769671493\n",
      "V159-->V152: r^2=0.9956763214995289\n",
      "V164-->V151: r^2=0.9860663006312356\n",
      "V167-->V168: r^2=0.9941251584652298\n",
      "V167-->V169: r^2=0.9894281484788802\n",
      "V167-->V170: r^2=0.9882629286913505\n",
      "V167-->V171: r^2=0.9858501590761509\n",
      "V167-->V172: r^2=0.9888924947831511\n",
      "V167-->V173: r^2=0.9885375345812399\n",
      "V167-->V174: r^2=0.987082207986866\n",
      "V167-->V175: r^2=0.9860959477103838\n",
      "V167-->V176: r^2=0.9920715568647689\n",
      "V167-->V177: r^2=0.9870798555720128\n",
      "V167-->V178: r^2=0.9814901551121872\n",
      "V167-->V179: r^2=0.9842617288868936\n",
      "V167-->V180: r^2=0.988840341264693\n",
      "V167-->V181: r^2=0.9934843398933043\n",
      "V167-->V182: r^2=0.9904360460435064\n",
      "V167-->V183: r^2=0.993049492398962\n",
      "V167-->V184: r^2=0.9876137266943126\n",
      "V167-->V185: r^2=0.9876056392218809\n",
      "V167-->V186: r^2=0.9880530916139937\n",
      "V167-->V187: r^2=0.9894728651871766\n",
      "V167-->V188: r^2=0.9810554185894104\n",
      "V167-->V189: r^2=0.9834376832287111\n",
      "V167-->V190: r^2=0.9887900255138964\n",
      "V167-->V191: r^2=0.9864614954193532\n",
      "V167-->V192: r^2=0.9863532089875306\n",
      "V167-->V193: r^2=0.9860775149151562\n",
      "V167-->V196: r^2=0.9855521628335056\n",
      "V167-->V198: r^2=0.9805574039488728\n",
      "V167-->V199: r^2=0.9891526556992358\n",
      "V167-->V200: r^2=0.9813773291374204\n",
      "V167-->V201: r^2=0.9824593112611536\n",
      "V167-->V205: r^2=0.9824177970434711\n",
      "V167-->V206: r^2=0.9836966121515667\n",
      "V167-->V211: r^2=0.9806565978099611\n",
      "V167-->V214: r^2=0.9830963391934772\n",
      "V167-->V216: r^2=0.9823544705226638\n",
      "V167-->V217: r^2=0.9847765755336901\n",
      "V167-->V219: r^2=0.9821260723416797\n",
      "V167-->V228: r^2=0.9800975127593409\n",
      "V168-->V167: r^2=0.9941251584652298\n",
      "V168-->V207: r^2=0.9805198039438056\n",
      "V169-->V194: r^2=0.9936466352129996\n",
      "V169-->V195: r^2=0.9942665356287889\n",
      "V169-->V197: r^2=0.992370614589405\n",
      "V169-->V208: r^2=0.9891640895830677\n",
      "V169-->V209: r^2=0.9901641569890385\n",
      "V169-->V210: r^2=0.9895238934953827\n",
      "V169-->V212: r^2=0.9873102073796918\n",
      "V169-->V213: r^2=0.9865833730267242\n",
      "V169-->V220: r^2=0.9849477322666902\n",
      "V169-->V223: r^2=0.9865896484491872\n",
      "V169-->V225: r^2=0.9863384025838343\n",
      "V169-->V227: r^2=0.982941756899103\n",
      "V169-->V230: r^2=0.9865417493514965\n",
      "V169-->V231: r^2=0.9832208972436219\n",
      "V169-->V232: r^2=0.9807483978274487\n",
      "V169-->V233: r^2=0.9825324549744733\n",
      "V169-->V240: r^2=0.9816341570560866\n",
      "V169-->V241: r^2=0.9827077552087737\n",
      "V169-->V242: r^2=0.985153267385853\n",
      "V169-->V243: r^2=0.9846348853791089\n",
      "V169-->V244: r^2=0.985153267385853\n",
      "V169-->V246: r^2=0.9850668981283014\n",
      "V169-->V247: r^2=0.9848020313601009\n",
      "V169-->V248: r^2=0.9837716311860966\n",
      "V169-->V249: r^2=0.9833641975467188\n",
      "V169-->V252: r^2=0.9838583656508373\n",
      "V169-->V254: r^2=0.9835613891964663\n",
      "V169-->V257: r^2=0.9845918816911967\n",
      "V169-->V258: r^2=0.9844892999108813\n",
      "V169-->V266: r^2=0.9803410938173786\n",
      "V169-->V269: r^2=0.9849158151038284\n",
      "V172-->V224: r^2=0.9805226589536603\n",
      "V177-->V226: r^2=0.9805067939111489\n",
      "V177-->V234: r^2=0.9816442099525317\n",
      "V180-->V215: r^2=0.9854719607408252\n",
      "V180-->V235: r^2=0.9805433442240804\n",
      "V180-->V237: r^2=0.9805915824913221\n",
      "V181-->V236: r^2=0.9817870026649396\n",
      "V181-->V238: r^2=0.9835895437337083\n",
      "V181-->V239: r^2=0.9834976137458652\n",
      "V186-->V260: r^2=0.981409029538315\n",
      "V202-->V263: r^2=0.9844866705906826\n",
      "V205-->V267: r^2=0.9810902422285334\n",
      "V205-->V268: r^2=0.9840792828952183\n",
      "V205-->V271: r^2=0.9814804041929501\n",
      "V205-->V272: r^2=0.9815492836730861\n",
      "V211-->V273: r^2=0.9877637891178455\n",
      "V211-->V275: r^2=0.9833368185744625\n",
      "V213-->V274: r^2=0.9805768019555225\n",
      "V214-->V276: r^2=0.9817679880307205\n",
      "V214-->V278: r^2=0.9831033928705192\n",
      "V217-->V221: r^2=0.9913846346056108\n",
      "V217-->V222: r^2=0.9893050834171284\n",
      "V217-->V229: r^2=0.9816386513226559\n",
      "V217-->V245: r^2=0.9809211281625703\n",
      "V217-->V253: r^2=0.983300727969418\n",
      "V217-->V259: r^2=0.9839773802552777\n",
      "V217-->V261: r^2=0.9836637351740722\n",
      "V217-->V262: r^2=0.986606134885357\n",
      "V217-->V270: r^2=0.984638734526924\n",
      "V219-->V255: r^2=0.9822192606055661\n",
      "V219-->V256: r^2=0.9823664494736449\n",
      "V220-->V250: r^2=0.9808053381431159\n",
      "V220-->V251: r^2=0.9808053381431159\n",
      "V229-->V218: r^2=0.987954775718258\n",
      "V234-->V277: r^2=0.9830329201191215\n",
      "V263-->V202: r^2=0.9844866705906826\n",
      "V264-->V265: r^2=0.9997120904579753\n",
      "V265-->V264: r^2=0.9997120904579753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V300-->V301: r^2=0.9864229915545116\n",
      "V301-->V300: r^2=0.9864229915545116\n",
      "V302-->V304: r^2=0.996271121947219\n",
      "V304-->V302: r^2=0.996271121947219\n",
      "V319-->V321: r^2=0.9846392022251858\n",
      "V321-->V319: r^2=0.9846392022251858\n",
      "V331-->V332: r^2=0.9922240144083385\n",
      "V331-->V333: r^2=0.9971864304180247\n",
      "V332-->V331: r^2=0.9922240144083385\n",
      "389 columns total\n",
      "123 columns left\n",
      "The set of remaining columns should be modified. Error: \"['isFraud'] not in index\"\n",
      "\u001b[1mThe summary of the train_transaction dataset:\u001b[0;0m\n",
      "The train_transaction dataset contains 123 columns\n",
      "There are 0 string categorical columns\n",
      "There are 81 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 42 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the train_transaction dataset **********\n",
      "\u001b[1mThe summary of the test_transaction dataset:\u001b[0;0m\n",
      "The test_transaction dataset contains 122 columns\n",
      "There are 0 string categorical columns\n",
      "There are 78 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 44 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the test_transaction dataset **********\n",
      "\u001b[1m\u001b[35mIf you have numeric features, it is a good idea to normalize numeric features. Use the following function for feature normalization :\n",
      "\u001b[m\u001b[32m\u001b[40mdataframe_dict, columns_set = flow.scale_data (dataframe_dict: dict, ignore_columns: list)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mignore_columns = ['id', 'target']\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.drop_correlated_columns(dataframe_dict, ignore_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_columns = [\"TransactionID\", \"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mThe summary of the train_transaction dataset:\u001b[0;0m\n",
      "The train_transaction dataset contains 123 columns\n",
      "There are 0 string categorical columns\n",
      "There are 81 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 42 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the train_transaction dataset **********\n",
      "\u001b[1mThe summary of the test_transaction dataset:\u001b[0;0m\n",
      "The test_transaction dataset contains 122 columns\n",
      "There are 0 string categorical columns\n",
      "There are 78 numeric categorical columns\n",
      "\u001b[1mNOTE: numeric categorical columns that contains more than 50 classes are considered numeric continuous features.\u001b[0;0m\n",
      "\u001b[1mNOTE: You can modify the threshold value if you want to consider more or less numeric categorical features as numeric continuous features.\u001b[0;0m\n",
      "There are 44 columns with numeric continuous values \n",
      "There are 0 columns that contain date\n",
      "There are 0 columns that contain valid nested JSON data\n",
      "There are 0 columns that contain other type of data\n",
      "********** End of the summary of the test_transaction dataset **********\n",
      "\u001b[1m\u001b[35mYour features are ready to train the model: \u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mIf you want to explore the data you can run one of the following functions: \u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35m1 . \u001b[m\u001b[32m\u001b[40mflow.exploring_data(dataframe_dict: dict, key_i: str)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mflow.exploring_data(dataframe_dict, 'train')\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35m2 . \u001b[m\u001b[32m\u001b[40mflow.comparing_statistics(dataframe_dict: dict)\u001b[m\u001b[m\n",
      "\u001b[1m\u001b[35mFor example: \u001b[m\u001b[32m\u001b[40mflow.comparing_statistics(dataframe_dict)\u001b[m\u001b[m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[35mYou can start training the model by applying the following function: \u001b[m\u001b[m\n",
      "\u001b[32m\u001b[40mmodel_index_list, save_models_dir, y_test = flow.training(parameters)\u001b[m\n",
      "parameters = { \n",
      " \"data\": {\n",
      " \"train\": {\"features\": train_dataframe, \"target\": train_target},\n",
      " \"valid\": {\"features\": valid_dataframe, \"target\": valid_target},\n",
      " \"test\": {\"features\": test_dataframe, \"target\": test_target},\n",
      " },\n",
      " \"split\": {\n",
      " \"method\": \"split\",  # \"method\":\"kfold\"\n",
      " \"split_ratios\": 0.2,  # fold_nr: 5 , \"split_ratios\": 0.2 # \"split_ratios\":(0.3,0.2)\n",
      " },\n",
      " \"model\": {\"type\": \"Ridge linear regression\",\n",
      " \"hyperparameters\": {\"alpha\": 1,  # alpha:optimize\n",
      " },\n",
      " },\n",
      " \"metrics\": [\"r2_score\", \"mean_squared_error\"]\n",
      " }\n"
     ]
    }
   ],
   "source": [
    "dataframe_dict, columns_set = flow.scale_data(dataframe_dict, ignore_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ad333f0c9e4cdd8287de0f7c13c56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='column_i', max=121), Output()), _dom_classes=('widget-in"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow.exploring_data(dataframe_dict, \"test_transaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb28514f898a4a609f6291effffb1bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='feature_nr', max=122), Output()), _dom_classes=('widget-"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "flow.comparing_statistics(dataframe_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = dataframe_dict[\"train_transaction\"].columns\n",
    "train_dataframe = dataframe_dict[\"train_transaction\"][\n",
    "    [x for x in columns_set[\"train_transaction\"][\"continuous\"] if x not in ignore_columns]]\n",
    "test_dataframe = dataframe_dict[\"test_transaction\"][\n",
    "    [x for x in columns_set[\"train_transaction\"][\"continuous\"] if x not in ignore_columns]]\n",
    "train_target = dataframe_dict[\"train_transaction\"][\"isFraud\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"data\": {\n",
    "        \"train\": {\"features\": train_dataframe, \"target\": train_target.to_numpy()},\n",
    "    },\n",
    "    \"split\": {\n",
    "        \"method\": \"kfold\",  # \"method\":\"kfold\"\n",
    "        \"fold_nr\": 5,  # foldnr:5 , \"split_ratios\": 0.8 # \"split_ratios\":(0.7,0.2)\n",
    "    },\n",
    "    \"model\": {\"type\": \"Logistic regression\",\n",
    "              \"hyperparameters\": {\"alpha\": \"optimize\",  # alpha:optimize\n",
    "                                  },\n",
    "              },\n",
    "    \"metrics\": [\"r2_score\", \"mean_squared_error\"],\n",
    "    \"predict\": {\n",
    "        \"test\": {\"features\": test_dataframe}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle is not provided: 'shuffle'\n",
      "random_state is not provided: 'random_state'\n",
      "fold_nr. 1\n",
      "The quality of the model using the dataset kfold 1\n",
      "dataset kfold 1: accuracy score: 0.98\n",
      "dataset kfold 1:  ROC AUC score: 50.0 %\n",
      "fold_nr. 2\n",
      "The quality of the model using the dataset kfold 2\n",
      "dataset kfold 2: accuracy score: 0.98\n",
      "dataset kfold 2:  ROC AUC score: 50.0 %\n",
      "fold_nr. 3\n",
      "The quality of the model using the dataset kfold 3\n",
      "dataset kfold 3: accuracy score: 0.9767\n",
      "dataset kfold 3:  ROC AUC score: 50.0 %\n",
      "fold_nr. 4\n",
      "The quality of the model using the dataset kfold 4\n",
      "dataset kfold 4: accuracy score: 0.98\n",
      "dataset kfold 4:  ROC AUC score: 50.0 %\n",
      "fold_nr. 5\n",
      "The quality of the model using the dataset kfold 5\n",
      "dataset kfold 5: accuracy score: 0.98\n",
      "dataset kfold 5:  ROC AUC score: 50.0 %\n",
      "mean R2 5 Folds:  -2.11\n",
      "mean MSE 5 Folds:  0.0207\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9807\n",
      "Evaluating the dataset: train:  ROC AUC score: 53.2 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9807\n",
      "Evaluating the dataset: train:  ROC AUC score: 53.2 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.98\n",
      "Evaluating the dataset: train:  ROC AUC score: 51.6 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9807\n",
      "Evaluating the dataset: train:  ROC AUC score: 53.2 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9807\n",
      "Evaluating the dataset: train:  ROC AUC score: 53.2 %\n",
      "train: The accuracy score: 0.98056\n",
      "train:  ROC AUC score: 52.879999999999995 %\n",
      "This is the end of the flow\n"
     ]
    }
   ],
   "source": [
    "model_index_list, save_models_dir, y_test = flow.training(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lighgbm = {\n",
    "    \"data\": {\n",
    "        \"train\": {\"features\": train_dataframe, \"target\": train_target.to_numpy()},\n",
    "    },\n",
    "    \"split\": {\n",
    "        \"method\": \"kfold\",  # \"method\":\"kfold\"\n",
    "        \"fold_nr\": 5,  # foldnr:5 , \"split_ratios\": 0.8 # \"split_ratios\":(0.7,0.2)\n",
    "    },\n",
    "    \"model\": {\"type\": \"lightgbm\",\n",
    "              \"hyperparameters\": dict(objective='binary', metric='cross-entropy', num_leaves=5,\n",
    "                                      boost_from_average=True,\n",
    "                                      learning_rate=0.05, bagging_fraction=0.99, feature_fraction=0.99, max_depth=-1,\n",
    "                                      num_rounds=10000, min_data_in_leaf=10, boosting='dart')\n",
    "              },\n",
    "    \"metrics\": [\"r2_score\", \"mean_squared_error\"],\n",
    "    \"predict\": {\n",
    "        \"test\": {\"features\": test_dataframe}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shuffle is not provided: 'shuffle'\n",
      "random_state is not provided: 'random_state'\n",
      "fold_nr. 1\n",
      "The quality of the model using the dataset kfold 1\n",
      "dataset kfold 1: accuracy score: 0.9833\n",
      "dataset kfold 1:  ROC AUC score: 82.4 %\n",
      "fold_nr. 2\n",
      "The quality of the model using the dataset kfold 2\n",
      "dataset kfold 2: accuracy score: 0.9867\n",
      "dataset kfold 2:  ROC AUC score: 82.2 %\n",
      "fold_nr. 3\n",
      "The quality of the model using the dataset kfold 3\n",
      "dataset kfold 3: accuracy score: 0.99\n",
      "dataset kfold 3:  ROC AUC score: 88.5 %\n",
      "fold_nr. 4\n",
      "The quality of the model using the dataset kfold 4\n",
      "dataset kfold 4: accuracy score: 0.9833\n",
      "dataset kfold 4:  ROC AUC score: 87.9 %\n",
      "fold_nr. 5\n",
      "The quality of the model using the dataset kfold 5\n",
      "dataset kfold 5: accuracy score: 0.9867\n",
      "dataset kfold 5:  ROC AUC score: 82.3 %\n",
      "mean R2 5 Folds:  34.13\n",
      "mean MSE 5 Folds:  0.0132\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9967\n",
      "Evaluating the dataset: train:  ROC AUC score: 96.7 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9973\n",
      "Evaluating the dataset: train:  ROC AUC score: 96.5 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.998\n",
      "Evaluating the dataset: train:  ROC AUC score: 97.3 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9967\n",
      "Evaluating the dataset: train:  ROC AUC score: 98.1 %\n",
      "The quality of the model using the Evaluating the dataset: train\n",
      "Evaluating the dataset: train: accuracy score: 0.9973\n",
      "Evaluating the dataset: train:  ROC AUC score: 96.8 %\n",
      "train: The accuracy score: 0.9972\n",
      "train:  ROC AUC score: 97.08000000000001 %\n",
      "This is the end of the flow\n"
     ]
    }
   ],
   "source": [
    "model_index_list, save_models_dir, y_test = flow.training(parameters_lighgbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
